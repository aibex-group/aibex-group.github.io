@article{Abbet2021,
 abstract = {Supervised learning is conditioned by the availability of  labeled data, which are especially expensive to acquire in  the field of medical image analysis. Making use of  open-source data for pre-training or using domain  adaptation can be a way to overcome this issue. However,  pre-trained networks often fail to generalize to new test  domains that are not distributed identically due to  variations in tissue stainings, types, and textures.  Additionally, current domain adaptation methods mainly rely  on fully-labeled source datasets. In this work, we propose  Self-Rule to Adapt (SRA) which takes advantage of  self-supervised learning to perform domain adaptation and  removes the burden of fully-labeled source datasets. SRA  can effectively transfer the discriminative knowledge  obtained from a few labeled source domain to a new target  domain without requiring additional tissue annotations. Our  method harnesses both domains’ structures by capturing  visual similarity with intra-domain and cross-domain  self-supervision. We show that our proposed method  outperforms baselines across diverse domain adaptation  settings and further validate our approach to our in-house  clinical cohort.},
 address = {Lübeck, Germany. 2021-07},
 author = {Abbet, Christian and Studer, Linda and Fischer, Andreas  and Dawson, Heather and Zlobec, Inti and Bozorgtabar,  Behzad and Thiran, Jean-Philippe},
 journal = {Proceedings of the  Medical Imaging with Deep Learning  (MIDL 2021), 7 ‑ 9 July 2021,  Lübeck, Germany},
 number = {CONFERENCE},
 pages = {16 p.},
 publisher = {7-9 July 2021},
 recid = {10969},
 title = {Self-rule to adapt : learning generalized features from  sparsely-labeled data using unsupervised domain adaptation  for colorectal cancer tissue phenotyping},
 url = {/research/papers/Abbet2021.pdf}
}

@article{Abbet2022,
 abstract = {In this paper, we present a fully automated system for  tumor-stroma ratio (TSR) scoring in line with current  recommendations for pathologists, based on tumor and  tumor-adjacent stroma tissue detection. In order to  evaluate the scoring system, we perform survival analysis  on 221 whole slide image from colorectal cancer patients.  We find that the whole slide image-level and region of  interest-level TSR are statistically significant predictors  of overall survival.},
 address = {Zurich, Switzerland. 2022-07},
 author = {Abbet, Christian and Studer, Linda and Zlobec, Inti and  Thiran, Jean-Philippe},
 journal = {Proceedings of Medical Imaging with Deep Learning Zürich,  6 – 8 July 2022, Zurich, Switzerland},
 number = {CONFERENCE},
 pages = {3 p.},
 publisher = {6-8 July 2022},
 recid = {10948},
 title = {Toward automatic tumor-stroma ratio assessment for  survival analysis in colorectal cancer},
 url = {/research/papers/Abbet2022.pdf}
}

@article{Abbet2022,
 abstract = {Supervised learning is constrained by the availability of  labeled data, which are especially expensive to acquire in  the field of digital pathology. Making use of open-source  data for pre-training or using domain adaptation can be a  way to overcome this issue. However, pre-trained networks  often fail to generalize to new test domains that are not  distributed identically due to tissue stainings, types, and  textures variations. Additionally, current domain  adaptation methods mainly rely on fully-labeled source  datasets. In this work, we propose Self-Rule to Multi-Adapt  (SRMA), which takes advantage of self-supervised learning  to perform domain adaptation, and removes the necessity of  fully-labeled source datasets. SRMA can effectively  transfer the discriminative knowledge obtained from a few  labeled source domain’s data to a new target domain without  requiring additional tissue annotations. Our method  harnesses both domains’ structures by capturing visual  similarity with intra-domain and cross-domain  self-supervision. Moreover, we present a generalized  formulation of our approach that allows the framework to  learn from multiple source domains. We show that our  proposed method outperforms baselines for domain adaptation  of colorectal tissue type classification in single and  multi-source settings, and further validate our approach on  an in-house clinical cohort. The code and trained models  are available open-source:  https://github.com/christianabbet/SRA.},
 address = {2022-07},
 author = {Abbet, Christian and Studer, Linda and Fischer, Andreas  and Dawson, Heather and Zlobec, Inti and Bozorgtabar,  Behzad and Thiran, Jean-Philippe},
 doi = {https://doi.org/10.1016/j.media.2022.102473},
 journal = {Medical Image Analysis},
 number = {ARTICLE},
 pages = {20 p.},
 recid = {10949},
 title = {Self-rule to multi-adapt : generalized multi-source  feature learning using unsupervised domain adaptation for  colorectal cancer tissue detection},
 url = {/research/papers/Abbet2022.pdf}
}

@article{Diaz2018,
 abstract = {The dynamic signature is a biometric trait widely used and  accepted for verifying a person's identity. Current  automatic signature-based biometric systems typically  require five, ten, or even more specimens of a person's  signature to learn intrapersonal variability sufficient to  provide an accurate verification of the individual's  identity. To mitigate this drawback, this paper proposes a  procedure for training with only a single reference  signature. Our strategy consists of duplicating the given  signature a number of times and training an automatic  signature verifier with each of the resulting signatures.  The duplication scheme is based on a sigma lognormal  decomposition of the reference signature. Two methods are  presented to create human-like duplicated signatures: the  first varies the strokes' lognormal parameters  (stroke-wise) whereas the second modifies their virtual  target points (target-wise). A challenging benchmark,  assessed with multiple state-of-the-art automatic signature  verifiers and multiple databases, proves the robustness of  the system. Experimental results suggest that our system,  with a single reference signature, is capable of achieving  a similar performance to standard verifiers trained with up  to five signature specimens.},
 address = {2018-01},
 author = {Diaz, Moises and Fischer, Andreas and Ferrer, Miguel A.  and Plamondon, Réjean},
 doi = {https://doi.org/10.1109/TCYB.2016.2630419},
 journal = {IEEE Transactions on Cybernetics},
 number = {ARTICLE},
 pages = {12 p.},
 recid = {3244},
 title = {Dynamic signature verification system based on one real  signature},
 url = {/research/papers/Diaz2018.pdf}
}

@article{Diesbach2022,
 abstract = {Images of historical Vietnamese steles allow historians to  discover invaluable information regarding the past of the  country, especially about the life of people in rural  villages. Due to the sheer amount of available stone  engravings and their diverseness, manual examination is  difficult and time-consuming. Therefore, automatic document  analysis methods based on machine learning could immensely  facilitate this laborious work. However, creating ground  truth for machine learning is also complex and  time-consuming for human experts, which is why synthetic  training samples greatly support learning while reducing  human effort. In particular, they can be used to train deep  neural networks for character detection and recognition. In  this paper, we present a method for creating synthetic  engravings and use it to create a new database composed of  26,901 synthetic Chu Nom characters in 21 different styles.  Using a machine learning model for unpaired image-to-image  translation, our approach is annotation-free, i.e. there is  no need for human experts to label character images. A user  study demonstrates that the synthetic engravings look  realistic to the human eye.},
 address = {Hyderabad, India. 2022-12},
 author = {Diesbach, Jonas and Fischer, Andreas and Bui, Marc and  Scius-Bertrand, Anna},
 journal = {Proceedings of International Conference on Frontiers in  Handwriting Recognition (ICFHR) 2022, 4-7 December 2022,   Hyderabad, India},
 number = {CONFERENCE},
 pages = {14 p.},
 publisher = {4-7 December 2022},
 recid = {10987},
 title = {Generating synthetic styled Chu nom characters},
 url = {/research/papers/Diesbach2022.pdf}
}

@article{Ertz2021,
 abstract = {In this work, we present a framework supported by mobile  and web apps and able to propose personalized pedestrian  routes that match user mobility profile considering  mobility impediments factors. We explain how these later  have been defined using a pedestrian-centric approach based  on travel experiences as perceived in the field by senior  citizens. Through workshops, six main factors that may  influence pedestrian route choices were revealed:  passability, obstacle in path, surface problem, security,  sidewalk width, slope. These categories were used to build  digital tools and guide a citizen participatory approach to  collect geolocated points of obstacle documented with  walkability information (picture, category, impact score,  free comment). We also involved citizens to evaluate these  information and especially senior referents for validation.  Finally we present how we connect these points of obstacle  with a pedestrian network based on OpenStreetMap to  configure a routing cost function. The framework has been  partially deployed in 2020 with limited people due to the  pandemic. Nonetheless, we share lessons learned from  interaction with citizens in the design of such a framework  whose underlying workflow is reproducible. We plan to  further assess its relevance and sustainability in the  future.},
 address = {Suttgart, Germany. 2021-09},
 author = {Ertz, Olivier and Fischer, Andreas and Ghorbel, Hatem and  Hüsser, Olivier and Sandoz, Romain and Scius-Bertrand,  Anna},
 doi = {https://doi.org/10.5194/isprs-archives-XLVI-4-W1-2021-29-2021},
 journal = {The International Archives of the Photogrammetry, Remote  Sensing and Spatial Information Sciences ; Proceedings of  the 6th International Conference on Smart Data and Smart  Cities},
 number = {CONFERENCE},
 pages = {6 p.},
 publisher = {15-17 September 2021},
 recid = {9393},
 title = {Citizen participation &amp;amp; digital tools to improve  pedestrian mobility in cities},
 url = {/research/papers/Ertz2021.pdf}
}

@article{Fischer2015,
 abstract = {The Sigma-Lognormal model of the Kinematic Theory of rapid  human movements allows us to represent online signatures  with an analytical neuromuscular model. It has been  successfully used in the past to generate synthetic  signatures in order to improve the performance of an  automatic verification system. In this paper, we attempt  for the first time to build a verification system based on  the model parameters themselves. For describing individual  lognormal strokes, we propose eighteen features which  capture cognitive psychomotor characteristics of the  signer. They are matched by means of dynamic time warping  to derive a dissimilarity measure for signature  verification. Promising initial results are reported for an  experimental evaluation on the SUSIG visual sub-corpus,  which contains some of the most skilled forgeries currently  available for research.},
 address = {Pointe-à-Pitre, Guadeloupe. 2015-06},
 author = {Fischer, Andreas and Plamondon, Réjean},
 journal = {Proceedings of the 17th Biennial Conference of the  International Graphonomics Society, International  Graphonomics Society (IGS), 21-24 June 2015,  Pointe-à-Pitre, Guadeloupe},
 number = {CONFERENCE},
 pages = {4 p.},
 publisher = {21-24 June 2015},
 recid = {10847},
 title = {A dissimilarity measure for on-line signature verification  based on the sigma-lognormal model},
 url = {/research/papers/Fischer2015.pdf}
}

@article{Fischer2015,
 abstract = {In order to cope with the exponential time complexity of  graph edit distance, several polynomial-time approximation  algorithms have been proposed in recent years. The  Hausdorff edit distance is a quadratic-time matching  procedure for labeled graphs which reduces the edit  distance to a correspondence problem between local  substructures. In its original formulation, nodes and their  adjacent edges have been considered as local substructures.  In this paper, we integrate a more general structural node  context into the matching procedure based on hierarchical  subgraphs. In an experimental evaluation on diverse graph  data sets, we demonstrate that the proposed generalization  of Hausdorff edit distance can significantly improve the  accuracy of graph classification while maintaining low  computational complexity.},
 address = {Springer. 2015-05},
 author = {Fischer, Andreas and Uchida, Seiichi and Frinken, Volkmar  and Riesen, Kaspar and Bunke, Horst},
 doi = {https://doi.org/10.1007/978-3-319-18224-7_15},
 journal = {Proceedings of International Workshop on Graph-Based  Representations in Pattern Recognition ; GbRPR 2015:  Graph-Based Representations in Pattern Recognition, 13-15  May 2015, Beijing, China},
 number = {CONFERENCE},
 pages = {10 p.},
 publisher = {Cham},
 recid = {10850},
 title = {Improving Hausdorff edit distance using structural node  context},
 url = {/research/papers/Fischer2015.pdf}
}

@article{Fischer2015,
 abstract = {In the field of automatic signature verification, a major  challenge for statistical analysis and pattern recognition  is the small number of reference signatures per user. Score  normalization, in particular, is challenged by the lack of  information about intra-user variability. In this paper, we  analyze several approaches to score normalization for  dynamic time warping and propose a new two-stage  normalization which detects simple forgeries in a first  stage and copes with more skilled forgeries in a second  stage. An experimental evaluation is conducted on two data  sets with different characteristics, namely the MCYT online  signature corpus, which contains over three hundred users,  and the SUSIG visual sub-corpus, which contains highly  skilled forgeries. The results demonstrate that score  normalization is a key component for signature verification  and that the proposed two-stage normalization achieves some  of the best results on these difficult data sets both for  random and for skilled forgeries.},
 address = {Tunis, Tunisia. 2015-11},
 author = {Fischer, Andreas and Diaz, Moises and Plamondon, Réjean  and Ferrer, Miguel A.},
 doi = {https://doi.org/10.1109/ICDAR.2015.7333760},
 journal = {Proceedings of the 2015 13th International Conference on  Document Analysis and Recognition (ICDAR), 23-26 August  2015, Tunis, Tunisia},
 number = {CONFERENCE},
 pages = {5 p.},
 publisher = {23-26 August 2015},
 recid = {10898},
 title = {Robust score normalization for DTW-based on-line signature  verification},
 url = {/research/papers/Fischer2015.pdf}
}

@article{Fischer2015,
 abstract = {What can be done with only one enrolled real hand-written  signature in Automatic Signature Verification (ASV)? Using  5 or 10 signatures for training is the most common case to  evaluate ASV. In the scarcely addressed case of only one  available signature for training, we propose to use  modified duplicates. Our novel technique relies on a fully  neuromuscular representation of the signatures based on the  Kinematic Theory of rapid human movements and its  Sigma-Lognormal model. This way, a real on-line signature  is converted into the Sigma-Lognormal model domain. The  model parameters are then varied to generate new duplicated  signatures.},
 address = {Tunis, Tunisia. 2015-11},
 author = {Fischer, Andreas and Diaz, Moises and Plamondon, Réjean  and Ferrer, Miguel A.},
 doi = {https://doi.org/10.1109/ICDAR.2015.7333838},
 journal = {Proceedings of 2015 13th International Conference on  Document Analysis and Recognition (ICDAR), 23-26 August  2015, Tunis, Tunisia},
 number = {CONFERENCE},
 pages = {5 p.},
 publisher = {23-26 August 2015},
 recid = {10900},
 title = {Towards an automatic on-line signature verifier using only  one reference per signer},
 url = {/research/papers/Fischer2015.pdf}
}

@article{Fischer2016,
 abstract = {Real-time interaction with augmented reality is a novel  material for dancers and choreographers to work with on  stage. Rather than focusing on a perfect synchronization  between dance and music, it allows the dancers to affect  their audiovisual environment and react to the change. In  this paper, we report the process and outcome of a  col-laborative effort between art and technology that has  explored this new material and resulted in the dance  performance Nautilus. We suggest an interaction method  based on a depth sensor and pixel-cloud avatars that allows  the dancers to interact reliably with an augmented reality  while moving freely on stage.},
 address = {Fribourg, Suisse. 2016-10},
 author = {Fischer, Andreas and Buchs, Pascal and Caon, Maurizio and  Khaled, Omar Abou and Mugellini, Elena and Grimm, Sara and  Meyer, Franziska and Wagner, Claudia and Bernasconi,  Valentine and Garz, Angelika},
 journal = {Actes de la 28ième conférence francophone sur  l’Interaction Homme-Machine (IHM'16), 25-28 octobre 2016,  Fribourg, Suisse},
 number = {CONFERENCE},
 pages = {pp. 50-57},
 publisher = {25-28 October 2016},
 recid = {11049},
 title = {Nautilus : real-time interaction between dancers and  augmented reality with pixel-cloud avatars},
 url = {/research/papers/Fischer2016.pdf}
}

@article{Fischer2017,
 abstract = {When using tablet computers, smartphones, or digital pens,  human users perform movements with a stylus or their  fingers that can be analyzed by the kinematic theory of  rapid human movements. In this paper, we present a  user-centered system for signature verification that  performs such a kinematic analysis to verify the identity  of the user. It is one of the first systems that is based  on a direct comparison of the elementary neuromuscular  strokes which are detected in the handwriting. Taking into  account the number of strokes, their similarity, and their  timing, the string edit distance is employed to derive a  dissimilarity measure for signature verification. On  several benchmark datasets, we demonstrate that this  neuromuscular analysis is complementary to a  well-established verification using dynamic time warping.  By combining both approaches, our verifier is able to  outperform current state-of-the-art results in on-line  signature verification.},
 address = {2017-04},
 author = {Fischer, Andreas and Plamondon, Réjean},
 doi = {https://doi.org/10.1109/THMS.2016.2634922},
 journal = {IEEE Transactions on Human-Machine Systems},
 number = {ARTICLE},
 pages = {12 p.},
 recid = {6225},
 title = {Signature verification based on the kinematic theory of  rapid human movements},
 url = {/research/papers/Fischer2017.pdf}
}

@article{Fischer2017,
 abstract = {Approximation of graph edit distance in polynomial time  enables us to compare large, arbitrarily labeled graphs for  structural pattern recognition. In a recent approximation  framework, bipartite graph matching (BP) has been proposed  to reduce the problem of edit distance to a cubic-time  linear sum assignment problem (LSAP) between local  substructures. Following the same line of research, first  attempts towards quadratic-time approximation have been  made recently, including a lower bound based on Hausdorff  matching (Hausdorff Edit Distance) and an upper bound based  on greedy assignment (Greedy Edit Distance). In this paper,  we compare the two approaches and derive a novel upper  bound (BP2) which combines advantages of both. In an  experimental evaluation on the IAM graph database  repository, we demonstrate that the proposed quadratic-time  methods perform equally well or, quite surprisingly, in  some cases even better than the cubic-time method.},
 address = {2017-02},
 author = {Fischer, Andreas and Riesen, Kaspar and Bunke, Horst},
 doi = {https://doi.org/10.1016/j.patrec.2016.06.014},
 journal = {Pattern Recognition Letters},
 number = {ARTICLE},
 pages = {8 p.},
 recid = {6226},
 title = {Improved quadratic time approximation of graph edit  distance by combining Hausdorff matching and greedy  assignment},
 url = {/research/papers/Fischer2017.pdf}
}

@article{Fischer2019,
 abstract = {The Kinematic Theory of rapid human movements analytically  describes pen tip movements as a sequence of elementary  strokes with lognormal speed. The theory has been confirmed  in a large number of experimental evaluations, achieving a  high reconstruction quality when compared with observed  trajectories and providing pertinent features for  biomedical applications as well as biometric  identification. So far, the Kinematic Theory has focused on  one-dimensional movements with the Delta-Lognormal model  and on two-dimensional movements with the Sigma-Lognormal  model. In this chapter, we present a model for movements in  three dimensions, which naturally extends the  Sigma-Lognormal approach. We evaluate our method on two  action recognition datasets and an air-writing dataset,  demonstrating a high reconstruction quality for modelling  rapid 3D movements in all cases.},
 address = {New Jersey. 2019-12},
 author = {Fischer, Andreas and Schindler, Roman and Bouillon, Manuel  and Plamondon, Réjean},
 doi = {https://doi.org/10.1142/9789811226830_0015},
 journal = {The lognormality principle and its applications in  e-security, e-learning and e-health},
 number = {CHAPTER},
 pages = {pp. 327-342},
 publisher = {World Scientific},
 recid = {10982},
 title = {Modeling 3D movements with the kinematic theory of rapid  human movements},
 url = {/research/papers/Fischer2019.pdf}
}

@article{Fischer2020,
 abstract = {Document image analysis or document recognition refers to  the process of extracting valuable information from  document images. Although a few optical character reading  systems were already available in the 1970’s, the  fundamental research activities on this challenging task  has mainly emerged with the development of the scanner  technologies in the 1980’s, which allowed affordable  document image acquisition. At that time, the main  applications were focused on office automation and the  interpretation of printed material…},
 address = {New Jersey. 2020-11},
 author = {Fischer, Andreas and Liwicki, Marcus and Ingold, Rolf},
 doi = {https://doi.org/10.1142/9789811203244_0001},
 journal = {Handwritten historical document analysis, recognition, and  retrieval - state of the art and future trends},
 number = {CHAPTER},
 pages = {8 p.},
 publisher = {World Scientific},
 recid = {11264},
 title = {Introduction},
 url = {/research/papers/Fischer2020.pdf}
}

@article{Fischer2020,
 address = {New Jersey. 2020-11},
 author = {Fischer, Andreas},
 doi = {https://doi.org/10.1142/9789811203244_0002},
 journal = {Handwritten historical document analysis, recognition, and  retrieval - state of the art and future trends},
 number = {CHAPTER},
 pages = {pp. 11-23},
 publisher = {World Scientific},
 recid = {11265},
 title = {IAM-HistDB a dataset of handwritten historical documents},
 url = {/research/papers/Fischer2020.pdf}
}

@article{Fischer2020,
 address = {New Jersey. 2020-11},
 author = {Fischer, Andreas},
 doi = {https://doi.org/10.1142/9789811203244_0005},
 journal = {Handwritten historical document analysis, recognition, and  retrieval - state of the art and future trends},
 number = {CHAPTER},
 pages = {pp. 67-80},
 publisher = {World Scientific},
 recid = {11266},
 title = {Automatic handwriting recognition in historical documents},
 url = {/research/papers/Fischer2020.pdf}
}

@article{Fischer2020,
 address = {New Jersey. 2020-11},
 author = {Fischer, Andreas and Liwicki, Marcus and Ingold, Rolf},
 doi = {https://doi.org/10.1142/9789811203244_0013},
 journal = {Handwritten historical document analysis, recognition, and  retrieval - state of the art and future trends},
 number = {CHAPTER},
 pages = {pp. 249-251},
 publisher = {World Scientific},
 recid = {11267},
 title = {Conclusions and future trends},
 url = {/research/papers/Fischer2020.pdf}
}

@article{Fischer2020,
 abstract = {In recent years, libraries and archives all around the  world have increased their efforts to digitize historical  manuscripts. To integrate the manuscripts into digital  libraries, pattern recognition and machine learning methods  are needed to extract and index the contents of the scanned  images.

The unique compendium describes the outcome of the  HisDoc research project, a pioneering attempt to study the  whole processing chain of layout analysis, handwriting  recognition, and retrieval of historical manuscripts. This  description is complemented with an overview of other  related research projects, in order to convey the current  state of the art in the field and outline future  trends.

This must-have volume is a relevant reference work  for librarians, archivists and computer scientists.},
 address = {New Jersey. 2020-11},
 author = {Fischer, Andreas and Liwicki, Marcus and Ingold, rolf},
 number = {BOOK},
 pages = {268 p.},
 publisher = {World Scientific},
 recid = {11268},
 title = {Handwritten historical document analysis, recognition, and  retrieval - state of the art and future trends},
 url = {/research/papers/Fischer2020.pdf}
}

@article{Fischer2021,
 address = {Interred Alpine Space. 2021-03},
 author = {Fischer, Andreas and Keller, Michael},
 journal = {AlpLinkBioEco (2021). Creating Bio-based Value in the  Alpine Space. Interreg Alpine Space.},
 number = {CHAPTER},
 pages = {pp. 20-26},
 publisher = {x},
 recid = {7757},
 title = {The VCG tool : knowledge base and methods},
 url = {/research/papers/Fischer2021.pdf}
}

@article{Fischer2021,
 abstract = {Graphs are an intuitive and natural way of representing  handwriting. Due to their high representational power, they  have shown high performances in different learning-free  document analysis tasks. While machine learning is rather  unexplored for graph representations, geometric deep  learning offers a novel framework that allows for  convolutional neural networks similar to the image domain.  In this work, we show that the concept of attribute  prediction can be adapted to the graph domain. We propose a  graph neural network to map handwritten word graphs to a  symbolic attribute space. This mapping allows to perform  query-by-example word spotting as it was also tackled by  other learning-free approaches in the graph domain.  Furthermore, our model is capable of query-by-string, which  is out of scope for other graph-based methods in the  literature. We investigate two variants of graph  convolutional layers and show that learning improves  performances considerably on two popular graph-based word  spotting benchmarks.},
 address = {Cham. 2021-09},
 author = {Fischer, Andreas and Fink, Gernot A.},
 doi = {https://doi.org/10.1007/978-3-030-86549-8_4},
 journal = {Proceedings of International Conference on Document  Analysis and Recognition (ICDAR 2021), 5-10 September 2021,  Lausanne, Switzerland},
 number = {CONFERENCE},
 pages = {15 p.},
 publisher = {Springer},
 recid = {10985},
 title = {Graph convolutional neural networks for learning attribute  representations for word spotting},
 url = {/research/papers/Fischer2021.pdf}
}

@article{Fornés2021,
 abstract = {This project explores the feasibility of remote patient  monitoring based on the analysis of 3D  movements captured  with smartwatches. We base our analysis on the Kinematic  Theory of Rapid Human Movement. We have validated our  research in a real case scenario for stroke rehabilitation  at the Guttmann Institute5 (neurorehabilitation hospital),  showing promising results. Our work could have a great  impact in remote healthcare applications, improving the  medical efficiency and reducing the healthcare costs.  Future steps include more clinical validation, developing  multi-modal analysis architectures (analysing data from  sensors, images, audio, etc.), and exploring the  application of our technology to monitor other  neurodegenerative diseases.},
 address = {2022-12},
 author = {Fornés, Alicia and Bensalah, Asma and Carmona-Duarte,  Cristina and Chen, Jialuo and Ferrer, Miguel A. and  Fischer, Andreas and Lladós, Josep and Martin, Cristina and  Opisso, Eloy and Plamondon, Réjean and Scius-Bertrand, Anna  and Tormos, Josep Maria},
 doi = {https://doi.org/10.1007/978-3-031-19745-1_16},
 journal = {Intertwining graphonomics with human movements ;  Proceedings of the 20th International Graphonomics Society,  IGS 2021, 7-9 June 2022, Las Palmas de Gran Canaria, Spain},
 number = {CONFERENCE},
 pages = {12 p.},
 recid = {13181},
 title = {The RPM3D project : 3D kinematics for remote patient  monitoring},
 url = {/research/papers/Fornés2021.pdf}
}

@article{Frei2023,
 abstract = {In digital pathology, cell-level tissue analyses are  widely used to better understand tissue composition and  structure. Publicly available datasets and models for cell  detection and classification in colorectal cancer exist but  lack the differentiation of normal and malignant epithelial  cells that are important to perform prior to any downstream  cell-based analysis. This classification task is  particularly difficult due to the high intra-class  variability of neoplastic cells. To tackle this, we present  here a new method that uses graph-based node classification  to take advantage of both local cell features and global  tissue architecture to perform accurate epithelial cell  classification. The proposed method demonstrated excellent  performance on F1 score (PanNuke: 1.0, TCGA: 0.98) and  performed significantly better than conventional computer  vision methods (PanNuke: 0.99, TCGA: 0.92).},
 address = {2023-07},
 author = {Frei, Ana Leni and Khan, Amjad and Studer, Linda and Zens,  Philipp and Lugli, Alessandro and Fischer, Andreas and  Zlobec, Inti},
 journal = {Proceedings of the Medical Imaging with Deep Learning  (MIDL), 10-12 July 2023, Nashville, USA},
 number = {CONFERENCE},
 pages = {5 p.},
 recid = {13132},
 title = {Local and global feature aggregation for accurate  epithelial cell classification using graph attention  mechanisms in histopathology images},
 url = {/research/papers/Frei2023.pdf}
}

@article{Frei2023,
 abstract = {In histopathology, histologic elements are not randomly  located across an image but organize into structured  patterns. In this regard, classification tasks or feature  extraction from histology images may require context  information to increase performance. In this work, we  explore the importance of keeping context information for a  cell classification task on Hematoxylin and Eosin (H&amp;E)  scanned whole slide images (WSI) in colorectal cancer. We  show that to differentiate normal from malignant epithelial  cells, the environment around the cell plays a critical  role. We propose here an image augmentation based on gamma  variations to guide deep learning models to focus on the  object of interest while keeping context information. This  augmentation method yielded more specific models and helped  to increase the model performance (weighted F1 score  with/without gamma augmentation respectively, PanNuke:  99.49 vs 99.37 and TCGA: 91.38 vs. 89.12, p &lt; 0.05).},
 address = {2023-07},
 author = {Frei, Ana Leni and Khan, Amjad and Zens, Philipp and  Lugli, Alessandro and Zlobec, Inti and Fischer, Andreas},
 journal = {Proceedings of Medical Imaging with Deep Learning (MIDL),  10-12 July 2023, Nashville, USA},
 number = {CONFERENCE},
 pages = {4 p.},
 recid = {13138},
 title = {GammaFocus : an image augmentation method to focus model  attention for classification},
 url = {/research/papers/Frei2023.pdf}
}

@article{Garz2016,
 abstract = {Recent advances in writer identification push the limits  by using increasingly complex methods relying on  sophisticated preprocessing, or the combination of already  complex descriptors. In this paper, we pursue a simpler and  faster approach to writer identification, introducing novel  descriptors computed from the geometrical arrangement of  interest points at different scales. They capture  orientation distributions and geometrical relationships of  script parts such as strokes, junctions, endings, and  loops. Thus, we avoid a fixed set of character appearances  as in standard codebook-based methods. The proposed  descriptors significantly cut down processing time compared  to existing methods, are simple and efficient, and can be  applied out-of-the-box to an unseen dataset. Evaluations on  widely-used datasets show their potential when applied by  themselves, and in combination with other descriptors.  Limitations of our method relate to the amount of data  needed to obtain reliable models.},
 address = {2016-09},
 author = {Garz, Angelika and Würsch, Marcel and Fischer, Andreas and  Ingold, Rolf},
 doi = {https://doi.org/10.2352/ISSN.2470-1173.2016.17.DRR-055},
 journal = {Electronic Imaging},
 number = {ARTICLE},
 pages = {12 p.},
 recid = {11003},
 title = {Simple and fast geometrical descriptors for writer  identification},
 url = {/research/papers/Garz2016.pdf}
}

@article{Garz2016,
 abstract = {Ground truth is both – indispensable for training and  evaluating document analysis methods, and yet very tedious  to create manually. This especially holds true for complex  historical manuscripts that exhibit challenging layouts  with interfering and overlapping handwriting. In this  paper, we propose a novel semi-automatic system to support  layout annotations in such a scenario based on document  graphs and a pen-based scribbling interaction. On the one  hand, document graphs provide a sparse page representation  that is already close to the desired ground truth and on  the other hand, scribbling facilitates an efficient and  convenient pen-based interaction with the graph. The  performance of the system is demonstrated in the context of  a newly introduced database of historical manuscripts with  complex layouts.},
 address = {Santorini, Greece. 2016-06},
 author = {Garz, Angelika and Seuret, Mathias and Simistira, Fotini  and Fischer, Andreas and Ingold, Rolf},
 doi = {https://doi.org/10.1109/DAS.2016.29},
 journal = {Proceedings of 12th IAPR Workshop on Document Analysis  Systems (DAS), 11-14 April 2016, Santorini, Greece},
 number = {CONFERENCE},
 pages = {6 p.},
 publisher = {11-14 April 2016},
 recid = {11004},
 title = {Creating ground truth for historical manuscripts with  document graphs and scribbling interaction},
 url = {/research/papers/Garz2016.pdf}
}

@article{Garz2017,
 abstract = {In historical manuscripts, humans can detect handwritten  words, lines, and decorations with lightness even if they  do not know the language or the script. Yet for automatic  processing this task has proven elusive, especially in the  case of handwritten documents with complex layouts, which  is why semiautomatic methods that integrate the human user  into the process are needed. In this paper, we introduce a  user-centered segmentation method based on document graphs  and scribbling interaction. The graphs capture a sparse  representation of the document's structure that can then be  edited by the user with a stylus on a touch-sensitive  screen. We evaluate the proposed method on a newly  introduced database of historical manuscripts with complex  layout and demonstrate, first, that the document graphs are  already close to the desired segmentation and, second, that  scribbling allows a natural and efficient interaction.},
 address = {2017-04},
 author = {Garz, Angelika and Seuret, Mathias and Fischer, Andreas  and Ingold, Rolf},
 doi = {https://doi.org/10.1109/THMS.2016.2634920},
 journal = {IEEE Transactions on Human-Machine Systems},
 number = {ARTICLE},
 pages = {13 p.},
 recid = {6224},
 title = {A user-centered segmentation method for complex historical  manuscripts based on document graphs},
 url = {/research/papers/Garz2017.pdf}
}

@article{Hernandez2015,
 abstract = {The development of predictive tools has been commonly  utilized as the most effective manner to prevent illnesses  that strike suddenly. Within this context, investigations  linking fine human motor control with brain stroke risk  factors are considered to have a high potential but they  are still in an early stage of research. The present paper  analyses neuromuscular features of oscillatory movements  based on the Omega-Lognormal model of the Kinematic Theory.  On a database of oscillatory movements from 120 subjects,  we demonstrate that the proposed features differ  significantly between subjects with and without brain  stroke risk factors. This promising result motivates the  development of predictive tools based on the  Omega-Lognormal model.},
 address = {Pointe-à-Pitre, Guadeloupe. 2015-06},
 author = {Hernandez, Albert Bou and Fischer, Andreas and Plamondon,  Réjean},
 journal = {Proceedings of the 17th Biennial Conference of the  International Graphonomics Society, International  Graphonomics Society (IGS), 21-24 June 2015,  Pointe-à-Pitre, Guadeloupe},
 number = {CONFERENCE},
 pages = {4 p.},
 publisher = {21-24 June 2015},
 recid = {10848},
 title = {Omega-lognormal analysis of oscillatory movements as a  function of brain stroke risk factors},
 url = {/research/papers/Hernandez2015.pdf}
}

@article{Howe2016,
 abstract = {Inkball models provide a tool for matching and comparison  of spatially structured markings such as handwritten  characters and words. Hidden Markov models offer a  framework for decoding a stream of text in terms of the  most likely sequence of causal states. Prior work with HMM  has relied on observation of features that are correlated  with underlying characters, without modeling them directly.  This paper proposes to use the results of inkball-based  character matching as a feature set input directly to the  HMM. Experiments indicate that this technique outperforms  other tested methods at handwritten word recognition on a  common benchmark when applied without normalization or text  deslanting.},
 address = {Shenzhen, China. 2017-01},
 author = {Howe, Nicholas R. and Fischer, Andreas and Wicht,  Baptiste},
 doi = {https://doi.org/10.1109/ICFHR.2016.0030},
 journal = {Proceedings of the 2016 15th International Conference on  Frontiers in Handwriting Recognition (ICFHR), 23-26 October  2016, Shenzhen, China},
 number = {CONFERENCE},
 pages = {pp. 96-101},
 publisher = {23-26 October 2016},
 recid = {11052},
 title = {Inkball models as features for handwriting recognition},
 url = {/research/papers/Howe2016.pdf}
}

@article{Jungo2023,
 abstract = {On-line handwritten character segmentation is often  associated with handwriting recognition and even though  recognition models include mechanisms to locate relevant  positions during the recognition process, it is typically  insufficient to produce a precise segmentation. Decoupling  the segmentation from the recognition unlocks the potential  to further utilize the result of the recognition. We  specifically focus on the scenario where the transcription  is known beforehand, in which case the character  segmentation becomes an assignment problem between sampling  points of the stylus trajectory and characters in the text.  Inspired by the k-means clustering algorithm, we view it  from the perspective of cluster assignment and present a  Transformer-based architecture where each cluster is formed  based on a learned character query in the Transformer  decoder block. In order to assess the quality of our  approach, we create character segmentation ground truths  for two popular on-line handwriting datasets, IAM-OnDB and  HANDS-VNOnDB, and evaluate multiple methods on them,  demonstrating that our approach achieves the overall best  results.},
 address = {2023-08},
 author = {Jungo, Michael and Wolf, Beat and Maksai, Andrii and  Musat, Claudiu and Fischer, Andreas},
 doi = {https://doi.org/10.1007/978-3-031-41676-7_6},
 journal = {Document analysis and recognition ICDAR 2023 ; Proceedings  of the 17th International Conference, 21-26 August 2023,  San José, CA, USA},
 number = {CONFERENCE},
 pages = {17 p.},
 recid = {13179},
 title = {Character queries : a transformer-based approach  to on-line handwritten character segmentation},
 url = {/research/papers/Jungo2023.pdf}
}

@article{Jungo2023,
 abstract = {Handwriting recognition is a key technology for accessing  the content of old manuscripts, helping to preserve  cultural heritage. Deep learning shows an impressive  performance in solving this task. However, to achieve its  full potential, it requires a large amount of labeled data,  which is difficult to obtain for ancient languages and  scripts. Often, a trade-off has to be made between ground  truth quantity and quality, as is the case for the recently  introduced Bullinger database. It contains an impressive  amount of over a hundred thousand labeled text line images  of mostly premodern German and Latin texts that were  obtained by automatically aligning existing page-level  transcriptions with text line images. However, the  alignment process introduces systematic errors, such as  wrongly hyphenated words. In this paper, we investigate the  impact of such errors on training and evaluation and  suggest means to detect and correct typical alignment  errors.},
 address = {2023-12},
 author = {Jungo, Michael and Vötglin, Lars and Fakhari, Atefeh and  Wegmann, Nathan and Ingold, Rolf and Fischer, Andreas and  Scius-Bertrand, Anna},
 doi = {https://doi.org/10.1145/3628797.3628976},
 journal = {SOICT '23: Proceedings of the 12th International Symposium  on Information and Communication Technology, 7-8 December  2023, Ho Chi Minh, Vietnam},
 number = {CONFERENCE},
 pages = {6 p.},
 recid = {13473},
 title = {Impact of the ground truth quality for handwriting  recognition},
 url = {/research/papers/Jungo2023.pdf}
}

@article{Keller2021,
 address = {2021-02},
 author = {Keller, Michael and Fischer, Andreas and Wessely, Dorian  and Mudaffer, Ashna},
 doi = {https://doi.org/10.13140/rg.2.2.25278.20802},
 journal = {Working Paper, February 2021, HES-SO//FR HEIA-FR, iCoSys,  PICC, INNOSQUARE, Business Upper Austria},
 number = {ARTICLE},
 pages = {12 p.},
 recid = {7326},
 title = {Bio-based business opportunities unearthed : the VCG  software tool},
 url = {/research/papers/Keller2021.pdf}
}

@article{Keller2021,
 address = {Interred Alpine Space. 2021-03},
 author = {Keller, Michael},
 journal = {AlpLinkBioEco (2021). Creating Bio-based Value in the  Alpine Space. Interreg Alpine Space.},
 number = {CHAPTER},
 pages = {pp.18-20},
 publisher = {x},
 recid = {7756},
 title = {Making the bioeconomy work : business opportunities and  value chains},
 url = {/research/papers/Keller2021.pdf}
}

@article{Khan2022,
 abstract = {Computer-aided diagnostics in histopathology are based on  the digitization of glass slides. However, heterogeneity  between the images generated by different slide scanners  can unfavorably affect the performance of computational  algorithms. Here, we evaluate the impact of scanner  variability on lymph node segmentation due to its clinical  importance in colorectal cancer diagnosis. 100 slides  containing 276 lymph nodes were digitized using 4 different  slide scanners, and 50 of the lymph nodes containing  metastatic cancer cells. These 400 scans were subsequently  annotated by 2 experienced pathologists to precisely label  lymph node boundary. Three different segmentation methods  were then applied and compared: Hematoxylin-channel-based  thresholding (HCT), Hematoxylin-based active contours  (HAC), and a convolution neural network (U-Net). Evaluation  of U-Net trained from both a single scanner and an ensemble  of all scanners was completed. Mosaic images based on  representative tiles from a scanner were used as a  reference image to normalize the new data from different  test scanners to evaluate the performance of a pre-trained  model. Fine-tuning was carried out by using weights of a  model trained on one scanner to initialize model weights  for other scanners. To evaluate the domain generalization,  domain adversarial learning and stain mix-up augmentation  were also implemented. Results show that fine-tuning and  domain adversarial learning decreased the impact of scanner  variability and greatly improved segmentation across  scanners. Overall, U-Net with stain mix-up (Matthews  correlation coefficient (MCC) = 0.87), domain adversarial  learning (MCC = 0.86), and HAC (MCC = 0.87) were shown to  outperform HCT (MCC = 0.81) for segmentation of lymph nodes  when compared against the ground truth. The findings of  this study should be considered for future algorithms  applied in diagnostic routines.},
 address = {2022-08},
 author = {Khan, Amjad and Janowczyk, Andrew and Müller, Felix and  Blank, Annika and Nguyen, Huu Giao and Abbet, Christian and  Studer, Linda and Lugli, Alessandro and Dawson, Heather and  Thiran, Jean-Philippe and Zlobec, Inti},
 doi = {https://doi.org/10.1016/j.jpi.2022.100127},
 journal = {Journal of Pathology Informatics},
 number = {ARTICLE},
 pages = {16 p.},
 recid = {10946},
 title = {Impact of scanner variability on lymph node segmentation  in computational pathology},
 url = {/research/papers/Khan2022.pdf}
}

@article{Kocher2019,
 abstract = {In sequence modeling tasks the token order matters, but  this information can be partially lost due to the  discretization of the sequence into data points. In this  paper, we study the imbalance between the way certain token  pairs are included in data points and others are not. We  denote this a token order imbalance (TOI) and we link the  partial sequence information loss to a diminished  performance of the system as a whole, both in text and  speech processing tasks. We then provide a mechanism to  leverage the full token order information—Alleviated TOI—by  iteratively overlapping the token composition of data  points. For recurrent networks, we use prime numbers for  the batch size to avoid redundancies when building batches  from overlapped data points. The proposed method achieved  state of the art performance in both text and speech  related tasks.},
 address = {Hong Kong, China. 2019-11},
 author = {Kocher, Noémien and Scuito, Christian and Tarantino,  Lorenzo and Lazaridis, Alexandros and Fischer, Andreas and  Musat, Claudiu},
 doi = {https://doi.org/10.18653/v1/K19-1083},
 journal = {Proceedings of the 23rd Conference on Computational  Natural Language Learning (CoNLL), 3-4 November 2019, Hong  Kong, China},
 number = {CONFERENCE},
 pages = {10 p.},
 publisher = {3-4 November 2019},
 recid = {4486},
 title = {Alleviating sequence information loss with data  overlapping and prime batch sizes},
 url = {/research/papers/Kocher2019.pdf}
}

@article{Le Bayon2021,
 abstract = {The importance of engineers is increasingly recognized in  soil science because of their implication in most important  pedological processes. Furthermore, they contribute to  ecological functions provided by soils in both natural and  human-modified environments. In this review, we focus on  the role of two ecosystem engineers: (1) plants, their root  system, and associated microorganisms and (2) earthworms.  First, we explain why they are considered as major soil  engineers, and which variables (texture, porosity,  nutrient, and moisture dynamics) control their activities  in space and time (hotspots and hot moments). Then, their  roles in three processes of soil formation are reviewed,  namely, rock and mineral weathering, soil structure  (formation, stabilization, and disintegration), and  bioturbation. For each of them, the involved mechanisms  that occur at different spatial scales (from local to  landscape) are presented. On one hand, tree uprooting plays  a key role in rock weathering and soil profile  bioturbation. In addition, living and dead roots also  contribute to rock alteration and aggregation. On the other  hand, earthworms are mainly involved in the formation of  aggregates and burrows through their bioturbation  activities and to a less extent in weathering processes.  The long-term effects of such mechanisms on soil  heterogeneity, soil development, and pathways of  pedogenesis are discussed. Finally, we show how these two  main ecosystem engineers contribute to provisioning and  regulating services. Through their physical activities of  burrowing and soil aggregation, earthworms and plants  increase plant productivity, water infiltration, and  climate warming mitigation. They act as catalysts and  provide, transform, and translocate organic matter and  nutrients throughout the soil profile. Finally, due to  inter- and intraspecific interactions and/or symbiosis with  microorganisms (arbuscular fungi, bacteria), they enhance  soil fertility, decrease parasitic action, and bioremediate  some pollutants. Future research is, however, still needed  for a better understanding of the relationships between  adequate soil management, agricultural practices, and soil  biota in a perspective of relevant maintenance and  durability of ecological services.},
 address = {American Geophysical Union (AGU). 2021-01},
 author = {Le Bayon, Renée-Claire and Bullinger, Géraldine and  Schomburg, Andreas and Turberg, Pascal and Brunner, Philip  and Schlaepfer, Rodolphe and Guenat, Claire},
 doi = {https://doi.org/10.1002/9781119563952.ch4},
 journal = {Hydrogeology, chemical weathering, and soil formation :  Geophysical Monograph Series},
 number = {CHAPTER},
 pages = {pp. 81-103},
 publisher = {USA},
 recid = {7761},
 title = {Earthworms, plants, and Soils},
 url = {/research/papers/Le Bayon2021.pdf}
}

@article{Linder2020,
 abstract = {This paper presents SwissCrawl, the largest Swiss German  text corpus to date. Composed of more than half a million  sentences, it was generated using a customized web scraping  tool that could be applied to other low-resource languages  as well. The approach demonstrates how freely available web  pages can be used to construct comprehensive text corpora,  which are of fundamental importance for natural language  processing. In an experimental evaluation, we show that  using the new corpus leads to significant improvements for  the task of language modeling. To capture new content, our  approach will run continuously to keep increasing the  corpus over time.},
 address = {Marseille, France. 2020-05},
 author = {Linder, Lucy and Jungo, Michael and Hennebert, Jean and  Musat, Claudiu and Fischer, Andreas},
 journal = {Proceedings of the 12th Conference on Language Resources  and Evaluation (LREC 2020), 11-16 May 2020, Marseille,  France},
 number = {CONFERENCE},
 pages = {6 p.},
 publisher = {11-16 May 2020},
 recid = {10975},
 title = {Automatic creation of text corpora for low-resource  languages from the internet : the case of swiss german},
 url = {/research/papers/Linder2020.pdf}
}

@article{Maergner2017,
 abstract = {Graphs provide a powerful representation formalism for  handwritten signatures, capturing local properties as well  as their relations. Yet, although introduced early for  signature verification, only a few current systems rely on  graph-based representations. A possible reason is the high  computational complexity involved for matching two general  graphs. In this paper, we introduce a novel structural  approach to offline signature verification using an  efficient cubic-time approximation of graph edit distance.  We put forward several ways of creating, normalizing, and  comparing signature graphs built from keypoints and  investigate their performance on three benchmark datasets.  The experiments demonstrate a promising performance of the  proposed structural approach when compared with the state  of the art.},
 address = {Kyoto, Japan. 2017-11},
 author = {Maergner, Paul and Riesen, Kaspar and Ingold, Kaspar and  Fischer, Andreas},
 doi = {https://doi.org/10.1109/ICDAR.2017.201},
 journal = {Proceedings of 2017 14th IAPR International Conference on  Document Analysis and Recognition, 9-15 November 2017,  Kyoto, Japan},
 number = {CONFERENCE},
 pages = {7 p.},
 publisher = {9-15 November 2017},
 recid = {8709},
 title = {A structural approach to offline signature verification  using graph edit distance},
 url = {/research/papers/Maergner2017.pdf}
}

@article{Maergner2018,
 abstract = {For handwritten signature verification, signature images  are typically represented with fixed-sized feature vectors  capturing local and global properties of the handwriting.  Graphbased representations offer a promising alternative,  as they are flexible in size and model the global structure  of the handwriting. However, they are only rarely used for  signature verification, which may be due to the high  computational complexity involved when matching two graphs.  In this paper, we take a closer look at two recently  presented structural methods for handwriting analysis, for  which efficient matching methods are available: keypoint  graphs with approximate graph edit distance and inkball  models. Inkball models, in particular, have never been used  for signature verification before. We investigate both  approaches individually and propose a combined verification  system, which demonstrates an excellent performance on the  MCYT and GPDS benchmark data sets when compared with the  state of the art.},
 address = {Niagara Falls, USA. 2018-08},
 author = {Maergner, Paul and Howe, Nicholas R. and Riesen, Kaspar  and Ingold, Rolf and Fischer, Andreas},
 journal = {Proceedings of ICFHR 2018, the 16th International  Conference on Frontiers in Handwriting Recognition, 5-8  August 2018, Niagara Falls, USA},
 number = {CONFERENCE},
 pages = {6 p.},
 publisher = {5-8 August 2018},
 recid = {3232},
 title = {Offline signature verification via structural methods :  graph edit distance and inkball models},
 url = {/research/papers/Maergner2018.pdf}
}

@article{Maergner2018,
 abstract = {Biometric authentication by means of handwritten  signatures is a challenging pattern recognition task, which  aims to infer a writer model from only a handful of genuine  signatures. In order to make it more difficult for a forger  to attack the verification system, a promising strategy is  to combine different writer models. In this work, we  propose to complement a recent structural approach to  offline signature verification based on graph edit distance  with a statistical approach based on metric learning with  deep neural networks. On the MCYT and GPDS benchmark  datasets, we demonstrate that combining the structural and  statistical models leads to significant improvements in  performance, profiting from their complementary  properties.},
 address = {Beijing, China. 2018-08},
 author = {Maergner, Paul and Pondenkandath, Vinaychandran and  Alberti, Michele and Liwicki, Marcus and Riesen, Kaspar and  Ingold, Rolf and Fischer, Andreas},
 doi = {https://doi.org/10.1007/978-3-319-97785-0_45},
 journal = {Proceedings of Joint IAPR International Workshop, S+SSPR  2018, Beijing, China, 17-19 August 2018},
 number = {CONFERENCE},
 pages = {11 p.},
 publisher = {17-19 August 2018},
 recid = {3233},
 title = {Offline signature verification by combining graph edit  distance and triplet networks},
 url = {/research/papers/Maergner2018.pdf}
}

@article{Maergner2019,
 abstract = {Offline signature verification is a challenging pattern  recognition task where a writer model is inferred using  only a small number of genuine signatures. A combination of  complementary writer models can make it more difficult for  an attacker to deceive the verification system. In this  work, we propose to combine a recent structural approach  based on graph edit distance with a statistical approach  based on deep triplet networks. The combination of the  structural and statistical models achieve significant  improvements in performance on four publicly available  benchmark datasets, highlighting their complementary  perspectives.},
 address = {2019-07},
 author = {Maergner, Paul and Pondenkandath, Vinaychandran and  Alberti, Michele and Liwicki, Marcus and Riesen, Kaspar and  Ingold, Rolf and Fischer, Andreas},
 doi = {https://doi.org/10.1016/j.patrec.2019.06.024},
 journal = {Pattern Recognition Letters},
 number = {ARTICLE},
 pages = {8 p.},
 recid = {4562},
 title = {Combining graph edit distance and triplet networks for  offline signature verification},
 url = {/research/papers/Maergner2019.pdf}
}

@article{Plamondon2023,
 abstract = {This invited special session of IGS 2023 presents the  works carried out at Laboratoire Scribens and some of its  collaborating laboratories. It summarises the 17 talks  presented in the colloquium #611 entitled « La  lognormalité: une fenêtre ouverte sur le contrôle  neuromoteur» (Lognormality: a window opened on neuromotor  control), at the 2023 conference of the Association  Francophone pour le Savoir (ACFAS) on May 10, 2023. These  talks covered a wide range of subjects related to the  Kinematic Theory, including key elements of the theory,  some gesture analysis algorithms that have emerged from it,  and its application to various fields, particularly in  biomedical engineering and human-machine interaction.},
 address = {2023-10},
 author = {Plamondon, Réjean and Bensalah, Asma and Lebel, Karina and  Salameh, Romeo and Séguin de Broin, Guillaume and O'Reilly,  Christian and Begon, Mickael and Desbiens, Olivier and  Beloufa, Youssef and Guy, Aymeric and Berio, Daniel and  Leymarie, Frederic Fol and Boyoguéno-Bidias, Simon-Pierre  and Fischer, Andreas and Zhang, Zigeng and Morin,  Marie-France and Alamargot, Denis and Rémi, Céline and  Faci, Nadir and Fortin, Raphaëlle and Simard, Marie-Noëlle  and Bazinet, Caroline},
 doi = {https://doi.org/10.1007/978-3-031-45461-5_15},
 journal = {Proceedings of the 21st International Conference of the  International Graphonomics Society, IGS 2023, 16-19 October  2023, Evora, Portugal ; Graphonomics in Human Body  Movement. Bridging Research and Practice from Motor Control  to Handwriting Analysis and Recognition},
 number = {CONFERENCE},
 pages = {54 p.},
 recid = {13210},
 title = {Lognormality : an open window on neuromotor control},
 url = {/research/papers/Plamondon2023.pdf}
}

@article{Principe2024,
 abstract = {Handwriting recognition enables the automatic  transcription of large volumes of digitized collections,  providing access to the content. However, regardless of the  system used, some recognition errors still oc-cur. With the  advancement of Large Language Models (LLMs), the ques-tion  arises whether these models can improve handwriting  recognition as a post-processing step. We have developed a  method for LLM-based post-correction and evaluated it on  three benchmark datasets, namely Washington, Bentham, and  IAM. We consistently achieved a character error rate  reduction of up to 30%, though we observed significant  vari-ability depending on the prompt and the LLM used.},
 address = {2024-12},
 author = {Principe, Jean Pool Pereyra and Fischer, Andreas and  Scius-Bertrand, Anna},
 journal = {Proceedings of SOICT 2024, The 13th International  Symposium on Information and Communication  Technology,  13-15 December 2024, Danang, Vietnam},
 number = {CONFERENCE},
 pages = {13 p.},
 recid = {15161},
 title = {Post-correction of handwriting recognition using large  language models},
 url = {/research/papers/Principe2024.pdf}
}

@article{Reza Ameri2018,
 abstract = {Keyword spotting enables content-based retrieval of  scanned historical manuscripts using search terms, which,  in turn, facilitates the indexation in digital libraries.  Recent approaches include graph-based representations that  capture the complex structure of handwriting. However, the  high representational power of graphs comes at the cost of  high computational complexity for graph matching. In this  article, we investigate the potential of Hausdorff edit  distance (HED) for keyword spotting. It is an efficient  quadratictime approximation of the graph edit distance. In  a comprehensive experimental evaluation with four types of  handwriting graphs and four benchmark datasets (George  Washington, Parzival, Botany, and Alvermann  Konzilsprotokolle), we demonstrate a strong performance of  the proposed HED-based method when compared with the state  of the art, both, in terms of precision and speed.},
 address = {2018-05},
 author = {Reza Ameri, Mohammad and Stauffer, Michael and Riesen,  Kaspar and Bui, Tien D. and Fischer, Andreas},
 doi = {https://doi.org/10.1016/j.patrec.2018.05.003},
 journal = {Pattern Recognition Letters},
 number = {ARTICLE},
 pages = {7 p.},
 recid = {3242},
 title = {Graph-based keyword spotting in historical manuscripts  using Hausdorff edit distance},
 url = {/research/papers/Reza Ameri2018.pdf}
}

@article{Riba2018,
 abstract = {Graph representations have been widely used in pattern  recognition thanks to their powerful representation  formalism and rich theoretical background. A number of  errortolerant graph matching algorithms such as graph edit  distance have been proposed for computing a distance  between two labelled graphs. However, they typically suffer  from a high computational complexity, which makes it  difficult to apply these matching algorithms in a real  scenario. In this paper, we propose an efficient graph  distance based on the emerging field of geometric deep  learning. Our method employs a message passing neural  network to capture the graph structure and learns a metric  with a siamese network approach. The performance of the  proposed graph distance is validated in two application  cases, graph classification and graph retrieval of  handwritten words, and shows a promising performance when  compared with (approximate) graph edit distance  benchmarks.},
 address = {Beijing, China. 2018-08},
 author = {Riba, Pau and Fischer, Andreas and Lladós, Josep and  Fornés, Alicia},
 journal = {ICPR 2018, the 24th International Conference on Pattern  Recognition, 20-24 August 2018, Beijing, China},
 number = {CONFERENCE},
 pages = {6 p.},
 publisher = {20-24 August 2018},
 recid = {3235},
 title = {Learning graph distances with message passing neural  networks},
 url = {/research/papers/Riba2018.pdf}
}

@article{Riba2021,
 abstract = {The emergence of geometric deep learning as a novel  framework to deal with graph-based representations has  faded away traditional approaches in favor of completely  new methodologies. In this paper, we propose a new  framework able to combine the advances on deep metric  learning with traditional approximations of the graph edit  distance. Hence, we propose an efficient graph distance  based on the novel field of geometric deep learning. Our  method employs a message passing neural network to capture  the graph structure, and thus, leveraging this information  for its use on a distance computation. The performance of  the proposed graph distance is validated on two different  scenarios. On the one hand, in a graph retrieval of  handwritten words i.e. keyword spotting, showing its  superior performance when compared with (approximate) graph  edit distance benchmarks. On the other hand, demonstrating  competitive results for graph similarity learning when  compared with the current state-of-the-art on a recent  benchmark dataset.},
 address = {2021-12},
 author = {Riba, Pau and Lladòs, Josep and Fornés, Alicia and  Fischer, Andreas},
 doi = {https://doi.org/10.1016/j.patcog.2021.108132},
 journal = {Pattern Recognition},
 number = {ARTICLE},
 pages = {11 p.},
 recid = {10973},
 title = {Learning graph edit distance by graph neural networks},
 url = {/research/papers/Riba2021.pdf}
}

@article{Riesen2015,
 abstract = {The basic idea of a recent graph matching framework is to  reduce the problem of graph edit distance (GED) to an  instance of a linear sum assignment problem (LSAP). The  optimal solution for this simplified GED problem can be  computed in cubic time and is eventually used to derive a  suboptimal solution for the original GED problem. Yet, for  large scale graphs and/or large scale graph sets the cubic  time complexity remains a severe handicap of this  procedure. Therefore, we propose to use suboptimal  algorithms – with quadratic rather than cubic time  complexity – for solving the underlying LSAP. In  particular, we introduce several greedy assignment  algorithms for approximating GED. In an experimental  evaluation we show that there is great potential for  further speeding up the GED computation. Moreover, we  empirically confirm that the distances obtained by this  procedure remain sufficiently accurate for graph based  pattern classification.},
 address = {Cham. 2015-05},
 author = {Riesen, Kaspar and Ferrer, Miquel and Fischer, Andreas and  Bunke, Horst},
 doi = {https://doi.org/10.1007/978-3-319-18224-7_1},
 journal = {Proceedings of International Workshop on Graph-Based  Representations in Pattern Recognition ; GbRPR 2015:  Graph-Based Representations in Pattern Recognition, 13-15  May 2015, Beijing, China},
 number = {CONFERENCE},
 pages = {10 p.},
 publisher = {Springer},
 recid = {10849},
 title = {Approximation of graph edit distance in quadratic time},
 url = {/research/papers/Riesen2015.pdf}
}

@article{Riesen2016,
 abstract = {Graph edit distance is one of the most popular graph  matching paradigms available. By means of a reformulation  of graph edit distance to an instance of a linear sum  assignment problem, the major drawback of this  dissimilarity model, viz. the exponential time complexity,  has been invalidated recently. Yet, the substantial  decrease of the computation time is at the expense of an  approximation error. The present paper introduces a novel  transformation that processes the underlying cost model  into a utility model. The benefit of this transformation is  that it enables the integration of additional information  in the assignment process. We empirically confirm the  positive effects of this transformation on three standard  graph data sets. That is, we show that the accuracy of a  distance based classifier can be improved with the proposed  transformation while the run time remains nearly  unaffected.},
 address = {Ulm, Germany. 2016-09},
 author = {Riesen, Kaspar and Fischer, Andreas and Bunke, Horst},
 doi = {https://doi.org/10.1007/978-3-319-46182-3_16},
 journal = {Proceedings of the 7th IAPR TC3 Workshop, Artificial  Neural Networks in Pattern Recognition (ANNPR) 2016, 28-30  September 2016, Ulm Germany},
 number = {CONFERENCE},
 pages = {pp. 185-194},
 publisher = {28-30 September 2016},
 recid = {11053},
 title = {Approximation of graph edit distance by means of a utility  matrix},
 url = {/research/papers/Riesen2016.pdf}
}

@article{Riesen2017,
 abstract = {The present paper is concerned with graph edit distance,  which is widely accepted as one of the most flexible graph  dissimilarity measures available. A recent algorithmic  framework for approximating the graph edit distance  overcomes the major drawback of this distance model, viz.  its exponential time complexity. Yet, this particular  approximation suffers from an overestimation of the true  edit distance in general. Overall aim of the present paper  is to improve the distance quality of this approximation by  means of a post-processing search procedure. The employed  search procedure is based on the idea of simulated  annealing, which turns out to be particularly suitable for  complex optimization problems. In an experimental  evaluation on several graph data sets the benefit of this  extension is empirically confirmed.},
 address = {Anacapri, Italy. 2017-05},
 author = {Riesen, Kaspar and Fischer, Andreas and Bunke, Horst},
 doi = {https://doi.org/10.1007/978-3-319-58961-9_20},
 journal = {Proceedings of the International Workshop on Graph-based  Representations in Pattern Recognition (GbRPR 2017), 16-18  May 2017, Anacapri, Italy ; Lecture Notes in Computer  Science},
 number = {CONFERENCE},
 pages = {10 p.},
 publisher = {16-18 May 2017},
 recid = {10981},
 title = {Improved graph edit distance approximation with simulated  annealing},
 url = {/research/papers/Riesen2017.pdf}
}

@article{Riesen2018,
 abstract = {The concept of graph edit distance constitutes one of the  most flexible graph matching paradigms available. The major  drawback of graph edit distance, viz. the exponential time  complexity, has been recently overcome by means of a  reformulation of the edit distance problem to a linear sum  assignment problem. However, the substantial speed up of  the matching is also accompanied by an approximation error  on the distances. Major contribution of this paper is the  introduction of a transformation process in order to  convert the underlying cost model into a utility model. The  benefit of this transformation is that it enables the  integration of additional information in the assignment  process. We empirically confirm the positive effects of  this transformation on five benchmark graph sets with  respect to the accuracy and run time of a distance based  classifier.},
 address = {2018-10},
 author = {Riesen, Kaspar and Fischer, Andreas and Bunke, Horst},
 doi = {https://doi.org/10.1007/s11063-017-9739-7},
 journal = {Neural Processing Letters},
 number = {ARTICLE},
 pages = {17 p.},
 recid = {10976},
 title = {On the impact of using utilities rather than costs for  graph matching},
 url = {/research/papers/Riesen2018.pdf}
}

@article{Schindler2018,
 abstract = {The Kinematic Theory of rapid human movements and its  Sigma-Lognormal model enables to model human gestures, in  particular complex handwriting patterns such as words,  signatures and free gestures. This paper investigates the  extension of the theory and its Sigma-Lognormal model from  two dimensions to three, taking into account new  acquisition modalities (motion capture), multiple subjects,  and unconstrained motions. Despite the increased complexity  and the new acquisition modalities, we demonstrate that the  Sigma-Lognormal model can be successfully generalized to  describe 3D human movements. Starting from the 2D model, we  replace circular with spherical motions to derive a  representation of unconstrained human movements with a new  3D Sigma-Lognormal model. First experiments show a high  reconstruction quality with an average signal-tonoise ratio  (SNR) of 18.52 dB on the HDM05 dataset. Gesture recognition  using dynamic time warping (DTW) achieves similar  recognition accuracies when using original and  reconstructed gestures, which confirms the high quality of  the proposed model.},
 address = {Montréal, Québec, Canada. 2018-05},
 author = {Schindler, Roman and Bouillon, Manuel and Plamondon,  Réjean and Fischer, Andreas},
 journal = {Proceedings of ICPRAI 2018 - International Conference on  Pattern Recognition and Artificial Intelligence,  Celebrating the 30th Anniversary of CENPARMI, 14-17 May  2018 + Public Lecture on 13 May 2018, Concordia University,  Montréal, Canada},
 number = {CONFERENCE},
 pages = {5 p.},
 publisher = {14-17 May 2018},
 recid = {3230},
 title = {Extending the Sigma-Lognormal model of the kinematic  theory to three dimensions},
 url = {/research/papers/Schindler2018.pdf}
}

@article{Schwab2016,
 abstract = {Méthodes et outils pour la rénovation énergétique de  l'enveloppe des immeubles d'habitation : L'assainissement  énergétique des immeubles d'habitation est un enjeu majeur  de la stratégie énergétique 2050 de la Confédération  suisse. Malgré la volonté politique, le taux de rénovation  énergétique reste relativement limité et le rythme ne  semble pas s'accélérer. Parmi les obstacles le coût des  travaux, le faible prix de l'énergie, les difficultés  techniques, les questions patrimoniales, la disponibilité  de spécialistes qualifiés, ou la pénurie de logements. Les  interventions ponctuelles sans vision d'ensemble sont la  norme. Lorsqu'un projet complet est mené à bien, il se  résume souvent à une mise à jour des installations  techniques, un remplacement des fenêtres et une isolation  périphérique. Ces solutions peut-être valables sur le plan  énergétique posent souvent des questions constructives,  patrimoniales, de physique du bâtiment ou encore de  durabilité. eREN a mené un travail sur l'enveloppe des  bâtiments basé sur une approche globale et  interdisciplinaire cherchant le meilleur équilibre entre  efficience énergétique, aspects constructifs et de physique  du bâtiment, économie, co-bénéfices et co-pertes et valeur  patrimoniale. Les typologies constructives des bâtiments  d'habitation collective en Suisse romande entre 1900 à 1990  ont été recensées. Cinq époques caractéristiques ont été  retenues : avant-guerre (1900- 1920), entre-deux-guerres  (1921 -1945), après-guerre (1946-1960), haute conjoncture  (1961 - 1975) et après crise pétrolière (1975 - 1990),  époque à partir de laquelle une prise de conscience au  sujet de la consommation d'énergie a vu le jour, débouchant  sur les premières normes en matière d'énergétique du  bâtiment. Chacune de ces époques présente des  caractéristiques architecturales et constructives propres.  Quinze typologies (modèles) ont été identifiées,  représentatives de la production de logements collectifs du  20e siècle en Suisse romande. Chacune est différente et  mérite d'être considérée avec respect. Intervenir sur un  bâtiment existant (même banal) présente des enjeux  patrimoniaux: le bâti ordinaire a toute son importance dans  la définition de l'identité de la ville. Et l'application  de solutions insuffisamment réfléchies peut être à  l'origine de nombreux problèmes. Dix bâtiments  représentatifs des typologies les plus courantes ont été  sélectionnés pour faire l'objet d'une étude de cas. L'état  existant a été analysé, puis une stratégie générale  d'intervention a été choisie pour chaque cas: préserver les  caractéristiques, reconstruire les caractéristiques,  ajouter de nouveaux éléments ou modifier l'image. Plusieurs  scénarios ont été développés pour chaque cas visant à  répondre à la stratégie adoptée tout en satisfaisant aux  exigences énergétiques fixées par la norme SIA 380/1 éd.  2009. Chaque scénario a été testé en matière thermique dans  une série d'allers et retours entre architectes et  ingénieurs qui ont débouché pour chacun des dix bâtiments  sur une solution satisfaisant les cinq critères définis.  Les scénarios ont été chiffrés afin de compléter l'étude  sur le plan économique. Tous atteignent les exigences  normatives en préservant le caractère architectural quand  cela s'imposait pour un coût comparable aux solutions plus  communément mises en œuvre, telles un crépi sur une  isolation périphérique. Rénovation énergétique respectueuse  de la substance architecturale du bâtiment à un coût  abordable ne rime donc pas avec mission impossible. Ce,  résultat a pu être atteint grâce à une collaboration  intense entre les différents spécialistes qui implique un  investissement que souvent les propriétaires hésitent à  consentir, bien qu'il ne représente qu'une fraction  relativement faible du coût total. L'étude montre aussi que  les coûts d'une rénovation énergétique demeurent très  élevés en regard des gains que l'on peut espérer réaliser  sur l'économie d'énergie, au tarif actuel de cette  dernière. Il est vrai que le volet énergétique de la  rénovation est souvent inclus dans un projet visant à  revaloriser un immeuble qui nécessite de toute façon des  travaux pour des questions de salubrité, de vétusté ou pour  la mise en valeur d'un potentiel inexploité. Il n'en  demeure pas moins que dans de nombreux cas où le bâtiment a  été entretenu et où les perspectives d'augmentation des  loyers sont faibles, une rénovation énergétique a peu de  chances d'être entreprise, faute d'incitation économique  suffisante. L'obligation d'atteindre les valeurs sévères  prescrites par la norme SIA 380/1 éd. 2009 dans le cadre de  la rénovation peut même avoir l'effet pervers de décourager  le propriétaire d'entreprendre certains travaux qui  amélioreraient notablement la situation à moindre coût sans  pour autant atteindre les limites légales. Le durcissement  des valeurs cibles pour la rénovation qui a commencé avec  la révision de 2009 de la norme et qui va selon toute  vraisemblance se poursuivre pourrait encore amplifier le  décalage entre des intentions en soi louables et le taux de  rénovation. Finalement inscrire dans la loi l'obligation  d'assainir l'enveloppe des bâtiments à court ou moyen terme  pourrait impliquer des coûts très élevés que de très  nombreux propriétaires ne seraient pas à même d'assumer,  faute de fonds de rénovation suffisant. Les collectivités  publiques sont d'ailleurs confrontées au même défi. Force  est aussi de constater que tant les mandataires que les  entreprises spécialisées de qualité feraient défaut devant  l'immensité de la tâche. Ces conclusions peuvent sembler  négatives. Elles ne le sont que si l'on s'arrête à ce  constat en baissant les bras. Nous pensons que les pistes  existent pour infléchir le cours des choses: la  réglementation et également les labels qui ont été  jusque-là axés principalement sur les constructions neuves  doivent beaucoup mieux prendre en compte les spécificités  de la rénovation du bâti existant et de ses limites ;  l'information, l'incitation et l'obligation doivent être  menées de front intelligemment et avec une vision à long  terme, à l'échelle de la durée de vie des bâtiments.  L'implication des spécialistes des différents domaines et  la prise en compte des particularités du système politique  suisse sont de mise afin d'éviter les écueils ; l'effort de  formation dans le domaine auprès des professionnels, des  entreprises, des apprentis et étudiants doit être renforcé  pour que la rénovation énergétique bénéficie de  professionnels qualifiés. Le jeu en vaut la chandelle. Et  quoi qu'il en soit, avons-nous le choix?},
 address = {Institut d'Architecture TRANSFORM, Haute école  d'ingénierie et d'architecture de Fribourg. 2016-01},
 author = {Schwab, Stefanie and Rime, Jean-Luc and Jaquerod, Grégory  and Rinquet, Lionel and Rey, Guillaume and Camponovo, Reto  and Gallinelli, Peter and Citherlet, Stéphane and Favre,  Didier and Périsset, Blaise and Morand, Gilbert-André and  Dervey, Sébastien},
 note = {Cette publication a été rédigée par un membre de l’ancien  institut IGT - Institut de Génie Thermique.},
 number = {BOOK},
 pages = {54 p.},
 publisher = {Fribourg, Suisse},
 recid = {5625},
 title = {Rénovation énergétique : approche globale pour l'enveloppe  du bâtiment},
 url = {/research/papers/Schwab2016.pdf}
}

@article{Scius-Bertrand2019,
 abstract = {Stone engravings in Historical Vietnamese steles allow  historians to study the life of common people in the  villages. Only recently, a large amount of images of such  engravings have become available. For supporting the  historians, automatic document analysis systems are needed  for reading the ancient Chu Nôm characters that are written  in columns from top to bottom. In this paper, we study the  problem of layout analysis, which is the first step of  automatic reading. Semantic segmentation is applied at  pixel-level to find the title, main text, label, and  reference number on the page using deep convolutional  neural networks. Afterwards, seam carving is used to  segment the text columns within the main text. We present  baseline results for hundred exemplary pages, discuss error  cases, and outline lines of future research.},
 address = {Sydney, Australia. 2019-09},
 author = {Scius-Bertrand, Anna and Voetglin, Lars and Alberti,  Michele and Fischer, Andreas and Bui, Marc},
 doi = {https://doi.org/10.1145/3352631.3352634},
 journal = {HIP '19 : Proceedings of the 5th International Workshop on  Historical Document Imaging and Processing, 20-21 September  2019, Sydney, Australia},
 number = {CONFERENCE},
 pages = {6 p.},
 publisher = {20-21 September 2019},
 recid = {4561},
 title = {Layout analysis and text column segmentation for  historical vietnamese steles},
 url = {/research/papers/Scius-Bertrand2019.pdf}
}

@article{Scius-Bertrand2021,
 abstract = {The current state of the art for automatic transcription  of historical manuscripts is typically limited by the  requirement of human-annotated learning samples, which are  are necessary to train specific machine learning models for  specific languages and scripts. Transcription alignment is  a simpler task that aims to find a correspondence between  text in the scanned image and its existing Unicode  counterpart, a correspondence which can then be used as  training data. The alignment task can be approached with  heuristic methods dedicated to certain types of  manuscripts, or with weakly trained systems reducing the  required amount of annotations. In this article, we propose  a novel learning-based alignment method based on fully  convolutional object detection that does not require any  human annotation at all. Instead, the object detection  system is initially trained on synthetic printed pages  using a font and then adapted to the real manuscripts by  means of self-training. On a dataset of historical  Vietnamese handwriting, we demonstrate the feasibility of  annotation-free alignment as well as the positive impact of  self-training on the character detection accuracy, reaching  a detection accuracy of 96.4% with a YOLOv5m model without  using any human annotation.},
 address = {2021-05},
 author = {Scius-Bertrand, Ann and Jungo, Michael and Wolf, Beat and  Fischer, Andreas and Bui, Marc},
 doi = {https://doi.org/10.3390/app11114894},
 journal = {Applied Sciences},
 number = {ARTICLE},
 pages = {18 p.},
 recid = {10972},
 title = {Transcription alignment of historical vietnamese  manuscripts without human-annotated learning samples},
 url = {/research/papers/Scius-Bertrand2021.pdf}
}

@article{Scius-Bertrand2021,
 abstract = {Images of Historical Vietnamese stone engravings provide  historians with a unique opportunity to study the past of  the country. However, due to the large heterogeneity of  thousands of images regarding both the text foreground and  the stone background, it is difficult to use automatic  document analysis methods for supporting manual  examination, especially with a view to the labeling effort  needed for training machine learning systems. In this  paper, we present a method for finding the location of Chu  Nom characters in the main text of the steles without the  need of any human annotation. Using self-calibration, fully  convolutional object detection methods trained on printed  characters are successfully adapted to the handwritten  image collection. The achieved detection results are  promising for subsequent document analysis tasks, such as  keyword spotting or transcription.},
 address = {Cham. 2021-09},
 author = {Scius-Bertrand, Anna and Jungo, Michael and Wolf, Beat and  Fischer, Andreas and Bui, Marc},
 doi = {https://doi.org/10.1007/978-3-030-86549-8_28},
 journal = {Proceedings of the International Conference on Document  Analysis and Recognition (ICDAR 2021), 5-10 September 2021,  Lausanne, Switzerland},
 number = {CONFERENCE},
 pages = {16 p.},
 publisher = {Springer},
 recid = {10983},
 title = {Annotation-free character detection in historical  vietnamese stele images},
 url = {/research/papers/Scius-Bertrand2021.pdf}
}

@article{Scius-Bertrand2022,
 abstract = {Finding key terms in scanned historical manuscripts is  invaluable for accessing our written cultural heritage.  While keyword spotting (KWS) approaches based on machine  learning achieve the best spotting results in the current  state of the art, they are limited by the fact that  annotated learning samples are needed to infer the writing  style of a particular manuscript collection. In this paper,  we propose an annotation-free KWS method that does not  require any labeled handwriting sample but learns from a  printed font instead. First, we train a deep convolutional  character detection system on synthetic pages using printed  characters. Afterwards, the structure of the detected  characters is modeled by means of graphs and is compared  with search terms using graph matching. We evaluate our  method for spotting logographic Chu Nom characters on the  newly introduced Kieu database, which is a historical  Vietnamese manuscripts containing 719 scanned pages of the  famous Tale of Kieu. Our results show that search terms can  be found with promising precision both when providing  handwritten samples (query by example) as well as printed  characters (query by string).},
 address = {Montreal, Canada. 2022-08},
 author = {Scius-Bertrand, Anna and Studer, Linda and Fischer,  Andreas and Bui, Marc},
 journal = {Proceedings of the S+SSPR 2022. IAPR Joint International  Workshops on Statistical Techniques in Pattern Recognition  (SPR 2022) and Structural and Syntactic Pattern Recognition  (SSPR 2022), 26-27 August 2022, Montreal, Canada},
 number = {CONFERENCE},
 pages = {10 p.},
 publisher = {26-27 August 2022},
 recid = {10986},
 title = {Annotation-free keyword spotting in historical Vietnamese  manuscripts using graph matching},
 url = {/research/papers/Scius-Bertrand2022.pdf}
}

@article{Scius-Bertrand2022,
 abstract = {Stone engravings on Vietnamese steles are an invaluable  resource for historians to study the life of the villagers  in the past. Thanks to pictures taken of stampings of the  steles, they can be investigated today in the form of  digital images. Automatic keyword spotting is a promising  means to access the textual content of the images, allowing  to retrieve steles that contain a certain query term. In  this paper, we present a complete pipeline for retrieving  Chu Nom characters in Vietnamese steles that operates fully  automatically on the original images, without the need for  preprocessing, segmentation, or human annotation. It  combines a self-calibration approach to character detection  using deep convolutional neural networks with a graph-based  approach to keyword spotting that compares templates of the  search term with detected characters based on structural  properties.},
 address = {New York, NY, USA. 2022-12},
 author = {Scius-Bertrand, Anna and Fischer, Andreas and Bui, Marc},
 doi = {https://doi.org/10.1145/3568562.3568606},
 journal = {SoICT 2022: The 11th International Symposium on  Information and Communication Technology, 1-3 December  2022, Hanoi, Vietnam},
 number = {CONFERENCE},
 pages = {7 p.},
 publisher = {Association fo Computing Machinery},
 recid = {11381},
 title = {Retrieving keywords in historical vietnamese stele images  without human annotations},
 url = {/research/papers/Scius-Bertrand2022.pdf}
}

@article{Scius-Bertrand2023,
 abstract = {Judging the quality of handwriting based on  visuo-structural criteria is fundamental for teachers when  accompanying children who are learning to write. Automatic  methods for quality assessment can support teachers when  dealing with a large number of handwritings, in order to  identify children who are having difficulties. In this  paper, we investigate the potential of graph-based  handwriting representation and graph matching to capture  visuo-structural features and determine the legibility of  cursive handwriting. On a comprehensive dataset of words  written by children aged from 3 to 11 years, we compare the  judgment of human experts with a graph-based analysis, both  with respect to classification and clustering. The results  are promising and highlight the potential of graph-based  methods for handwriting evaluation.},
 address = {Cham. 2023-10},
 author = {Scius-Bertrand, Anna and Rémi, Céline and Biabiany,  Emmanuel and Nagau, Jimmy and Fischer, Andreas},
 doi = {https://doi.org/10.1007/978-3-031-45461-5_6},
 journal = {Proceedings of the 21st International Conference of the  International Graphonomics Society, IGS 2023, 16-19 October  2023, Evora, Portugal ; Graphonomics in Human Body  Movement. Bridging Research and Practice from Motor Control  to Handwriting Analysis and Recognition},
 number = {CONFERENCE},
 pages = {14 p.},
 publisher = {Springer},
 recid = {13130},
 title = {Towards visuo-structural handwriting evaluation based  on graph matching},
 url = {/research/papers/Scius-Bertrand2023.pdf}
}

@article{Scius-Bertrand2023,
 abstract = {In order to access the rich cultural heritage conveyed in  Vietnamese steles, automatic reading of stone engravings  would be a great support for historians, who are analyzing  tens of thousands of stele images. Approaching the  challenging problem with deep learning alone is difficult  because the data-driven models require large representative  datasets with expert human annotations, which are not  available for the steles and costly to obtain. In this  article, we present a hybrid approach to spot keywords in  stele images that combines data-driven deep learning with  knowledge-based structural modeling and matching of Chu Nom  characters. The main advantage of the proposed method is  that it is annotation-free, i.e. no human data annotation  is required. In an experimental evaluation, we demonstrate  that keywords can be successfully spotted with a mean  average precision of more than 70% when a single engraving  style is considered.},
 address = {2023-04},
 author = {Scius-Bertrand, Anna and Bui, Marc and Fischer, Andreas},
 doi = {https://doi.org/10.31449/inf.v47i3.4785},
 journal = {Informatica},
 number = {ARTICLE},
 pages = {12 p.},
 recid = {13131},
 title = {A hybrid deep learning approach to keyword spotting in  vietnamese stele images},
 url = {/research/papers/Scius-Bertrand2023.pdf}
}

@article{Scius-Bertrand2023,
 abstract = {One of the main challenges of automatically transcribing  large collections of handwritten letters is to cope with  the high variability of writing styles present in the  collection. In particular, the writing styles of  non-frequent writers, who have contributed only few  letters, are often missing in the annotated learning  samples used for training handwriting recognition systems.  In this paper, we introduce the Bullinger dataset for  writer adaptation, which is based on the Heinrich Bullinger  letter collection from the 16th century, using a subset of  3,622 annotated letters (about 1.2 million words) from 306  writers. We provide baseline results for handwriting  recognition with modern recognizers, before and after the  application of standard techniques for supervised  adaptation of frequent writers and self-supervised  adaptation of non-frequent writers.},
 address = {2023-08},
 author = {Scius-Bertrand, Anna and Ströbel, Phillip and Volk, Martin  and Hodel, Tobias and Fischer, Andreas},
 doi = {https://doi.org/10.1007/978-3-031-41676-7_23},
 journal = {Document analysis and recognition ICDAR 2023 ; Proceedings  of the 17th International Conference, 21-26 August 2023,  San José, CA, USA},
 number = {CONFERENCE},
 pages = {14 p.},
 recid = {13180},
 title = {The Bullinger dataset : a writer adaptation challenge},
 url = {/research/papers/Scius-Bertrand2023.pdf}
}

@article{Scius-Bertrand2024,
 abstract = {With the advent of end-to-end models and the remarkable  performance of foundation models, the question arises  regarding the relevance of preliminary steps, such as  layout analysis and optical character recognition (OCR),  for information extraction from document images. We attempt  to provide some answers through experiments conducted on a  new database of food labels. The goal is to extract  nutritional values from cellphone pictures taken in grocery  stores. We compare the results of OCR-free models that take  the raw images as input (Donut and GPT-4-Vision) with  two-stage systems that first perform OCR and then extract  information using large language models (LLMs) from the  recognized text (Mistral, GPT-3, and GPT-4). To assess the  impact of layout analysis, we applied the same systems to  three different views of the image: the original full  image, a large manual crop containing the entire food  label, and a small crop focusing on the relevant nutrition  information. Comparative experiments are also conducted on  the CORD database of receipts. Our results demonstrate that  although OCR-free models achieve a remarkable performance,  they still require some guidance regarding the layout, and  two-stage systems achieve better results overall.},
 address = {Cham. 2024-09},
 author = {Scius-Bertrand, Anna and Fakhari, Atefeh and Vötglin, lars  and Cabral, Daniel Ribeiro and Fischer, Andreas},
 doi = {https://doi.org/10.1007/978-3-031-70546-5_11},
 journal = {Proceedings of the 18th International Conference, 30  August – 4 September 2024, Athens, Greece},
 number = {CONFERENCE},
 pages = {16 p.},
 publisher = {Springer},
 recid = {15159},
 title = {Are layout analysis and OCR still useful for document  information extraction using foundation models ?},
 url = {/research/papers/Scius-Bertrand2024.pdf}
}

@article{Scius-Bertrand2024,
 abstract = {Classifying scanned documents is a challenging problem  that involves image, layout, and text analysis for document  understanding. Nevertheless, for certain benchmark  datasets, notably RVL-CDIP, the state of the art is closing  in to near-perfect performance when considering hundreds of  thousands of training samples. With the advent of large  language models (LLMs), which are excellent few-shot  learners, the question arises to what extent the document  classification problem can be addressed with only a few  training samples, or even none at all. In this paper, we  investigate this question in the context of zero-shot  prompting and few-shot model fine-tuning, with the aim of  reducing the need for human-annotated training samples as  much as possible.},
 address = {Cham. 2024-12},
 author = {Scius-Bertrand, Anna and Jungo, Michael and Vötglin, Lars  and Spat, Jean-Marc and Fischer, Andreas},
 doi = {https://doi.org/10.1007/978-3-031-78495-8_10},
 journal = {Proceedings of the 27th International Conference, ICPR  2024, 1-5 December 2024, Kolkata, India, Part XIX},
 number = {CONFERENCE},
 pages = {15 p.},
 publisher = {Springer},
 recid = {15160},
 title = {Zero-shot prompting and few-shot fine-tuning : revisiting  document image classification using large language models},
 url = {/research/papers/Scius-Bertrand2024.pdf}
}

@article{Seuret2015,
 abstract = {The term "historical documents" encompasses an enormous  variety of document types considering different scripts,  languages, writing supports, and degradation degrees. For  automatic processing with machine learning and pattern  recognition methods, it would be ideal to share labeled  learning samples and trained statistical models across  similar documents, avoiding a retraining from scratch for  every historical document anew. In this paper, we propose  using the reconstruction error of autoencoders to compare  historical manuscripts with the goal of clustering them  according to their visual appearance. A low reconstruction  error suggests visual similarity between a new manuscript  and a known manuscript, for which the autoencoder was  trained in an unsupervised fashion. Preliminary experiments  conducted on 10 different manuscripts written with ink on  parchment demonstrate the ability of the reconstruction  error to group similar writing styles. For discriminating  between Carolingian and cursive script, in particular,  near-perfect results are reported.},
 address = {Nancy, France. 2015-08},
 author = {Seuret, Mathias and Fischer, Andreas and Garz, Angelika  and Liwicki, Marcus and Ingold, Rolf},
 doi = {https://doi.org/10.1145/2809544.2809558},
 journal = {Proceedings of HIP '15: Proceedings of the 3rd  International Workshop on Historical Document Imaging and  Processing, 22 August 2022, Nancy, France},
 number = {CONFERENCE},
 pages = {7 p.},
 publisher = {22 August 2015},
 recid = {10894},
 title = {Clustering historical documents based on the  reconstruction error of autoencoders},
 url = {/research/papers/Seuret2015.pdf}
}

@article{Spoto2021,
 abstract = {Automatic handwriting recognition for historical documents  is a key element for making our cultural heritage available  to researchers and the general public. However, current  approaches based on machine learning require a considerable  amount of annotated learning samples to read ancient  scripts and languages. Producing such ground truth is a  laborious and time-consuming task that often requires human  experts. In this paper, to cope with a limited amount of  learning samples, we explore the impact of using synthetic  text line images to support the training of handwriting  recognition systems. For generating text lines, we consider  lineGen, a recent GAN-based approach, and for handwriting  recognition, we consider HTR-Flor, a state-of-the-art  recognition system. Different meta-learning strategies are  explored that schedule the addition of synthetic text line  images to the existing real samples. In an experimental  evaluation on the well-known Bentham dataset as well as the  newly introduced Bullinger dataset, we demonstrate a  significant improvement of the recognition performance when  combining real and synthetic samples.},
 address = {2022-12},
 author = {Spoto, Martin and Wolf, Beat and Fischer, Andreas and  Scius-Bertrand, Anna},
 doi = {https://doi.org/10.1007/978-3-031-19745-1_5},
 journal = {Proceedings of the 20th International Conference of the  International Graphonomics Society, IGS 2021, Intertwining  Graphnomics with Human Movements,  -9 June 2022, Las Palmas  de Gran Canaria},
 number = {CONFERENCE},
 pages = {15 p.},
 recid = {13205},
 title = {Improving handwriting recognition for historical documents  using synthetic text lines},
 url = {/research/papers/Spoto2021.pdf}
}

@article{Stammet2022,
 abstract = {Büchi Automata on infinite words present many interesting  problems and are used frequently in program verification  and model checking. A lot of these problems on Büchi  automata are computationally hard, raising the question if  a learning-based data-driven analysis might be more  efficient than using traditional algorithms. Since Büchi  automata can be represented by graphs, graph neural  networks are a natural choice for such a learning-based  analysis. In this paper, we demonstrate how graph neural  networks can be used to reliably predict basic properties  of Büchi automata when trained on automatically generated  random automata datasets.},
 address = {2022-07},
 author = {Stammet, Christophe and Dotti, Prisca and Ultes-Nitsche,  Ulrich and Fischer, Andreas},
 doi = {https://doi.org/10.48550/arxiv.2206.09619},
 journal = {Proceedings of the 4th International Workshop on Learning  and Automata (LearnAut 2022), 4 July 2022, Paris, France},
 number = {CONFERENCE},
 pages = {10 p.},
 recid = {13144},
 title = {Analyzing Büchi automata with graph neural networks},
 url = {/research/papers/Stammet2022.pdf}
}

@article{Stammet2023,
 abstract = {The universality check of Büchi automata is a foundational  problem in automata-based formal verification, closely  related to the complementation problem, and is known to be  PSPACE-complete. This article introduces a novel approach  for creating labelled datasets of Büchi automata concerning  their universality. We start with small automata, where the  universality check can still be algorithmically performed  within a reasonable timeframe, and then apply  transformations that provably preserve (non-)universality  while increasing their size. This approach enables the  generation of large datasets of labelled Büchi automata  without the need for an explicit and computationally  intensive universality check. We subsequently employ these  generated datasets to train Graph Neural Networks (GNNs)  for the purpose of classifying automata with respect to  their (non-)universality. The classification results  indicate that such a network can learn patterns related to  the behaviour of Büchi automata that facilitate the  recognition of universality. Additionally, our results on  randomly generated automata, which were not constructed  using the transformation techniques, demonstrate the  network’s potential in classifying Büchi automata with  respect to universality, extending its applicability beyond  cases generated using a specific technique.},
 address = {Piscataway, NJ, USA. 2023-12},
 author = {Stammet, Christophe and Ultes-Nitsche, Ulrich and Fischer,  Andreas},
 doi = {https://doi.org/10.1109/ACCESS.2023.3339538},
 journal = {IEEE Access},
 number = {ARTICLE},
 pages = {15 p.},
 publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
 recid = {13472},
 title = {Universality of Büchi automata : analysis with graph  neural networks},
 url = {/research/papers/Stammet2023.pdf}
}

@article{Stauffer2016,
 abstract = {The amount of handwritten documents that is digitally  available is rapidly increasing. However, we observe a  certain lack of accessibility to these documents especially  with respect to searching and browsing. This paper aims at  closing this gap by means of a novel method for keyword  spotting in ancient handwritten documents. The proposed  system relies on a keypoint-based graph representation for  individual words. Keypoints are characteristic points in a  word image that are represented by nodes, while edges are  employed to represent strokes between two keypoints. The  basic task of keyword spotting is then conducted by a  recent approximation algorithm for graph edit distance. The  novel framework for graph-based keyword spotting is tested  on the George Washington dataset on which a  state-of-the-art reference system is clearly outperformed.},
 address = {Mérida, Mexico. 2016-11},
 author = {Stauffer, Michael and Riesen, Kaspar and Fischer, Andreas},
 doi = {https://doi.org/10.1007/978-3-319-49055-7_50},
 journal = {Proceedings of Joint IAPR International Workshops on  Statistical Techniques in Pattern Recognition (SPR) and  Structural and Syntactic Pattern Recognition (SSPR), 29  November-2 December 2016, Mérida, Mexico},
 number = {CONFERENCE},
 pages = {pp. 564-573},
 publisher = {26 November-2 December 2016},
 recid = {11050},
 title = {Graph-based keyword spotting in historical handwritten  documents},
 url = {/research/papers/Stauffer2016.pdf}
}

@article{Stauffer2016,
 abstract = {For several decades graphs act as a powerful and flexible  representation formalism in pattern recognition and related  fields. For instance, graphs have been employed for  specific tasks in image and video analysis, bioinformatics,  or network analysis. Yet, graphs are only rarely used when  it comes to handwriting recognition. One possible reason  for this observation might be the increased complexity of  many algorithmic procedures that take graphs, rather than  feature vectors, as their input. However, with the rise of  efficient graph kernels and fast approximative graph  matching algorithms, graph-based handwriting representation  could become a versatile alternative to traditional  methods. This paper aims at making a seminal step towards  promoting graphs in the field of handwriting recognition.  In particular, we introduce a set of six different graph  formalisms that can be employed to represent handwritten  word images. The different graph representations for words,  are analysed in a classification experiment (using a  distance based classifier). The results of this word  classifier provide a benchmark for further investigations.},
 address = {Mérida, Mexico. 2016-11},
 author = {Stauffer, Michael and Fischer, Andreas and Riesen, Kaspar},
 doi = {https://doi.org/10.1007/978-3-319-49055-7_49},
 journal = {Proceedings of Joint IAPR International Workshops on  Statistical Techniques in Pattern Recognition (SPR) and  Structural and Syntactic Pattern Recognition (SSPR), 29  November-2 December 2016, Mérida, Mexico},
 number = {CONFERENCE},
 pages = {pp. 553-563},
 publisher = {29 November-2 December 2016},
 recid = {11051},
 title = {A novel graph database for handwritten word images},
 url = {/research/papers/Stauffer2016.pdf}
}

@article{Stauffer2017,
 abstract = {The present paper is concerned with a graph-based system  for Keyword Spotting (KWS) in historical documents. This  particular system operates on segmented words that are in  turn represented as graphs. The basic KWS process employs  the cubic-time bipartite matching algorithm (BP). Yet, even  though this graph matching procedure is relatively  efficient, the computation time is a limiting factor for  processing large volumes of historical manuscripts. In  order to speed up our framework, we propose a novel fast  rejection heuristic. This heuristic compares the node  distribution of the query graph and the document graph in a  polar coordinate system. This comparison can be  accomplished in linear time. If the node distributions are  similar enough, the BP matching is actually carried out  (otherwise the document graph is rejected). In an  experimental evaluation on two benchmark datasets we show  that about 50% or more of the matchings can be omitted with  this procedure while the KWS accuracy is not negatively  affected.},
 address = {Anacapri, Italy. 2017-05},
 author = {Stauffer, Michael and Fischer, Andreas and Riesen, Kaspar},
 doi = {https://doi.org/10.1007/978-3-319-58961-9_8},
 journal = {Lecture Notes in Computer Science ; Proceedings of  International Workshop on Graph-based Representations in  Pattern Recognition (GbRPR 2017), 16-18 May 2017, Anacapri,  Italy},
 number = {CONFERENCE},
 pages = {pp. 83-93},
 publisher = {16-18 May 2017},
 recid = {8296},
 title = {Speeding-up graph-based keyword spotting in historical  handwritten documents},
 url = {/research/papers/Stauffer2017.pdf}
}

@article{Stauffer2017,
 abstract = {About ten years ago, a novel graph edit distance framework  based on bipartite graph matching has been introduced. This  particular framework allows the approximation of graph edit  distance in cubic time. This, in turn, makes the concept of  graph edit distance also applicable to larger graphs. In  the last decade the corresponding paper has been cited more  than 360 times. Besides various extensions from the  methodological point of view, we also observe a great  variety of applications that make use of the bipartite  graph matching framework. The present paper aims at giving  a first survey on these applications stemming from six  different categories (which range from document analysis,  over biometrics to malware detection).},
 address = {Anacapri, Italy. 2017-05},
 author = {Stauffer, Michael and Tschachtli, Thomas and Fischer,  Andreas and Riesen, Kaspar},
 doi = {https://doi.org/10.1007/978-3-319-58961-9_22},
 journal = {Lecture Notes in Computer Science ; Proceedings of  International Workshop on Graph-based Representations in  Pattern Recognition (GbRPR 2017), 16-18 May 2017, Anacapri,  Italy},
 number = {CONFERENCE},
 pages = {pp. 242-252},
 publisher = {16-18 May 2017},
 recid = {8297},
 title = {A survey on applications of bipartite graph edit distance},
 url = {/research/papers/Stauffer2017.pdf}
}

@article{Stauffer2017,
 abstract = {Keyword Spotting (KWS) offers a convenient way to improve  the accessibility to historical handwritten documents by  retrieving search terms in scanned document images. The  approach for KWS proposed in the present paper is based on  segmented word images that are represented by means of  different types of graphs. The actual keyword spotting is  based on matching a query graph with a set of document  graphs using the concept of graph edit distance. In  particular, we propose to employ ensemble methods for KWS  with graphs. That is, a query graph is not matched against  one but several different graphs representing the same  document word. Eventually, we use different strategies to  combine these individual graph dissimilarities. In an  experimental evaluation on two benchmark datasets, the  proposed ensemble methods outperform the individual  ensemble members as well as four state-of-the-art reference  systems based on dynamic time warping.},
 address = {Kyoto, Japan. 2017-11},
 author = {Stauffer, Michael and Fischer, Andreas and Riesen, Kaspar},
 doi = {https://doi.org/10.1109/ICDAR.2017.122},
 journal = {Proceedings of the 2017 14th IAPR International Conference  on Document Analysis and Recognition (ICDAR), 9-15 November  2017, Kyoto, Japan},
 number = {CONFERENCE},
 pages = {7 p.},
 publisher = {9-15 November 2017},
 recid = {8711},
 title = {Ensembles for graph-based keyword spotting in historical  handwritten documents},
 url = {/research/papers/Stauffer2017.pdf}
}

@article{Stauffer2018,
 abstract = {Scanned handwritten historical documents are often not  well accessible due to the limited feasibility of automatic  full transcriptions. Thus, Keyword Spotting (KWS) has been  proposed as an alternative to retrieve arbitrary query  words from this kind of documents. In the present paper,  word images are represented by means of graphs. That is, a  graph is used to represent the inherent topological  characteristics of handwriting. The actual keyword spotting  is then based on matching a query graph with all document  graphs. In particular, we make use of a fast graph matching  algorithm that considers the contextual substructure of  nodes. The motivation for this inclusion of node context is  to increase the overall KWS accuracy. In an experimental  evaluation on four historical documents, we show that the  proposed procedure clearly outperforms diverse other  template-based reference systems. Moreover, our novel  framework keeps up or even outperforms many  state-of-the-art learning-based KWS approaches.},
 address = {Vienna, Austria. 2018-04},
 author = {Stauffer, Michael and Fischer, Andreas and Riesen, Kaspar},
 doi = {https://doi.org/10.1109/DAS.2018.31},
 journal = {Proceedings of DAS 2018 : 13th IAPR International Workshop  on Document Analysis Systems, 24-27 April 2018, Vienna,  Austria},
 number = {CONFERENCE},
 pages = {6 p.},
 publisher = {24-27 April 2018},
 recid = {3231},
 title = {Graph-based keyword spotting in historical documents using  context-aware Hausdorff edit distance},
 url = {/research/papers/Stauffer2018.pdf}
}

@article{Stauffer2018,
 abstract = {In many public and private institutions, the  digitalization of handwritten documents has progressed  greatly in recent decades. As a consequence, the number of  handwritten documents that are available digitally is  constantly increasing. However, accessibility to these  documents in terms of browsing and searching is still an  issue as automatic full transcriptions are often not  feasible. To bridge this gap, Keyword Spotting (KWS) has  been proposed as a flexible and error-tolerant alternative  to full transcriptions. KWS provides unconstrained  retrievals of keywords in handwritten documents that are  acquired either online or offline. In general, offline KWS  is regarded as the more difficult task when compared to  online KWS where temporal information on the writing  process is also available. The focus of this chapter is on  handwritten historical documents and thus on offline KWS.  In particular, we review and compare different  state-of-the-art as well as novel approaches for  template-based KWS. In contrast to learning-based KWS,  template-based KWS can be applied to documents without any  a priori learning of a model and is thus regarded as the  more flexible approach.},
 address = {2018-03},
 author = {Stauffer, Michael and Fischer, Andreas and Riesen, Kaspar},
 doi = {https://doi.org/10.1007/978-3-319-74322-6_13},
 journal = {Business Information Systems and Technology 4.0},
 number = {ARTICLE},
 pages = {15 p.},
 recid = {3236},
 title = {Searching and browsing in historical documents : state of  the art and novel approaches for template-based keyword  spotting},
 url = {/research/papers/Stauffer2018.pdf}
}

@article{Stauffer2018,
 abstract = {In the last decades historical handwritten documents have  become increasingly available in digital form. Yet, the  accessibility to these documents with respect to browsing  and searching remained limited as full automatic  transcription is often not possible or not sufficiently  accurate. This paper proposes a novel reliable approach for  template-based keyword spotting in historical handwritten  documents. In particular, our framework makes use of  different graph representations for segmented word images  and a sophisticated matching procedure. Moreover, we extend  our method to a spotting ensemble. In an exhaustive  experimental evaluation on four widely used benchmark  datasets we show that the proposed approach is able to keep  up or even outperform several state-of-the-art methods for  template- and learning-based keyword spotting.},
 address = {2018-09},
 author = {Stauffer, Michael and Riesen, Kaspar and Fischer, Andreas},
 doi = {https://doi.org/10.1016/j.patcog.2018.04.001},
 journal = {Pattern Recognition},
 number = {ARTICLE},
 pages = {14 p.},
 recid = {3240},
 title = {Keyword spotting in historical handwritten documents based  on graph matching},
 url = {/research/papers/Stauffer2018.pdf}
}

@article{Stauffer2018,
 abstract = {The accessibility to handwritten historical documents is  often constrained by the limited feasibility of automatic  full transcriptions. Keyword Spotting (KWS), that allows to  retrieve arbitrary query words from documents, has been  proposed as alternative. In the present paper, we make use  of graphs for representing word images. The actual keyword  spotting is thus based on matching a query graph with all  documents graphs. However, even with relative fast  approximation algorithms the shear amount of matchings  might limit the practical application of this approach. For  this reason we present two novel filters with linear time  complexity that allow to substantially reduce the number of  graph matchings actually required. In particular, these  filters estimate a graph dissimilarity between a query  graph and all document graphs based on their node and edge  distribution in a polar coordinate system. Eventually, all  graphs from the document with distributions that differ to  heavily from the query’s node/edge distribution are  eliminated. In an experimental evaluation on four different  historical documents, we show that about 90% of the  matchings can be omitted, while the KWS accuracy is not  negatively affected.},
 address = {2018-03},
 author = {Stauffer, Michael and Fischer, Andreas and Riesen, Kaspar},
 doi = {https://doi.org/10.1016/j.patrec.2018.03.030},
 journal = {Pattern Recognition Letters},
 number = {ARTICLE},
 recid = {3241},
 title = {Filters for graph-based keyword spotting in historical  handwritten documents},
 url = {/research/papers/Stauffer2018.pdf}
}

@article{Stauffer2019,
 abstract = {In recent years, different approaches for handwriting  recognition that are based on graph representations have  been proposed (e.g. graph-based keyword spotting or  signature verification). This trend is mostly due to the  availability of novel fast graph matching algorithms, as  well as the inherent flexibility and expressivity of graph  data structures when compared to vectorial representations.  That is, graphs are able to directly adapt their size and  structure to the size and complexity of the respective  handwritten entities. However, the vast majority of the  proposed approaches match the graphs from a global  perspective only. In the present paper, we propose to match  the underlying graphs from different local perspectives and  combine the resulting assignments by means of Dynamic Time  Warping. Moreover, we show that the proposed approach can  be readily combined with global matchings. In an  experimental evaluation, we employ the novel method in a  signature verification scenario on two widely used  benchmark datasets. On both datasets, we empirically  confirm that the proposed approach outperforms  state-of-theart methods with respect to both accuracy and  runtime.},
 address = {Sydney, New South Wales, Australia. 2019-09},
 author = {Stauffer, Michael and Maergner, Paul and Fischer, Andreas  and Ingold, Rolf and Riesen, Kaspar},
 journal = {Proceedings of ICDAR 2019 : 15th International Conference  on Document Analysis and Recognition, 20-25 september 2019,   Sydney, Australia},
 number = {CONFERENCE},
 pages = {8 p.},
 publisher = {20-25 september 2019},
 recid = {4558},
 title = {Offline signature verification using structural dynamic  time warping},
 url = {/research/papers/Stauffer2019.pdf}
}

@article{Stauffer2019,
 abstract = {Due to the high availability and applicability,  handwritten signatures are an eminent biometric  authentication measure in our life. To mitigate the risk of  a potential misuse, automatic signature verification tries  to distinguish between genuine and forged signatures. Most  of the available signature verification approaches make use  of vectorial rather than graph-based representations of the  handwriting. This is rather surprising as graphs offer some  inherent advantages. Graphs are, for instance, able to  directly adapt their size and structure to the size and  complexity of the respective handwritten entities.  Moreover, several fast graph matching algorithms have been  proposed recently that allow to employ graphs also in  domains with large amounts of data. The present paper  proposes to use different graph embedding approaches in  conjunction with a recent graph-based signature  verification framework. That is, signature graphs are not  directly matched with each other, but first compared with a  set of predefined prototype graphs, in order to obtain a  dissimilarity  representation. In an experimental  evaluation, we employ the proposed method on two widely  used benchmark datasets. On both datasets, we empirically  confirm that the learning-free graph embedding outperforms  state-of-the-art methods with respect to both accuracy and  runtime.},
 address = {Stockholm, Sweden. 2019-05},
 author = {Stauffer, Michael and Fischer, Andreas and Maergner, Paul  and Riesen, Kaspar},
 doi = {https://doi.org/10.1145/3345336.3345346},
 journal = {Proceedings of the ICBEA 2019 : 3rd International  Conference on Biometric Engineering and Applications, 29-31  May 2019, Stockholm, Sweden},
 number = {CONFERENCE},
 pages = {8 p.},
 publisher = {29-31 May 2019},
 recid = {4559},
 title = {Graph embedding for offline handwritten signature  verification},
 url = {/research/papers/Stauffer2019.pdf}
}

@article{Stauffer2019,
 abstract = {In contrast to statistical representations, graphs offer  some inherent advantages when it comes to handwriting  representation. That is, graphs are able to adapt their  size and structure to the individual handwriting and  represent binary relationships that might exist within the  handwriting. We observe an increasing number of graph-based  keyword spotting frameworks in the last years. In general,  keyword spotting allows to retrieve instances of an  arbitrary query in documents. It is common practice to  optimise keyword spotting frameworks for each document  individually, and thus, the overall generalisability  remains somehow questionable. In this paper, we focus on  this question by conducting a cross-evaluation experiment  on four handwritten historical documents. We observe a  direct relationship between parameter settings and the  actual handwriting. We also propose different ensemble  strategies that allow to keep up with individually  optimised systems without a priori knowledge of a certain  manuscript. Such a system can potentially be applied to new  documents without prior optimisation.},
 address = {Tours, France. 2019-06},
 author = {Stauffer, Michael and Maergner, Paul and Fischer, Andreas  and Riesen, Kaspar},
 doi = {https://doi.org/10.1007/978-3-030-20081-7_5},
 journal = {Lecture Notes in Computer Science ; Proceedings of 12th  IAPR-TC-15 International Workshop, GbRPR 2019: Graph-based  representations in pattern recognition, 19-21 June 2019,  Tours, France},
 number = {CONFERENCE},
 pages = {11 p.},
 publisher = {19-21 June 2019},
 recid = {4560},
 title = {Cross-evaluation of graph-based keyword spotting in  handwritten historical documents},
 url = {/research/papers/Stauffer2019.pdf}
}

@article{Ströbel2023,
 address = {2023-03},
 author = {Ströbel, Philip and Hodel, Tobias and Fischer, Andreas and  Scius-Bertrand, Anna and Wolf, Beat and Janka, Anna and  Widmer, Jonas and Scheurer, Patricia and Volk, Martin},
 doi = {https://doi.org/10.5281/zenodo.7715356},
 journal = {Digital Humanities im deutschsprachigen Raum 2023  (DHd2023): Open Humanities, Open Culture, 13-17 März 2023,  Trier, Germany, Belval, Luxembourg},
 number = {CONFERENCE},
 pages = {5 p.},
 recid = {13139},
 title = {Bullingers Briefwechsel zugänglich machen : Stand der  Handschriftenerkennung},
 url = {/research/papers/Ströbel2023.pdf}
}

@article{Studer2019,
 abstract = {Pathologists study tissue morphology in order to correctly  diagnose diseases such as colorectal cancer. This task can  be very time consuming, and automated systems can greatly  improve the precision and speed with which a diagnosis is  established. Explainable algorithms and results are key to  successful implementation of these methods into routine  diagnostics in the medical field. In this paper, we propose  a graphbased approach for intestinal gland classification.  It leverages the high representational power of graphs for  describing geometrical and topological properties of the  glands. A novel, publicly available image and graph dataset  is introduced based on cell segmentation of healthy and  dysplastic H&amp;E stained intestinal glands from pT1  colorectal cancer. The graphs are compared using an  approximate graph edit distance and are classified using  the k-nearest neighbours algorithm. With this method, we  achieve a classification accuracy of 83.3%.},
 address = {Shenzhen, China. 2019-10},
 author = {Studer, Linda and Toneyan, Shushan and Zlobec, Inti and  Dawson, Heather and Fischer, Andreas},
 journal = {Proceedings of MICCAI 2019, 13-17 October 2019, Shenzhen,  China},
 number = {CONFERENCE},
 pages = {8 p.},
 publisher = {13-17 October 2019},
 recid = {4556},
 title = {Graph-based classification of intestinal glands in  colorectal cancer tissue images},
 url = {/research/papers/Studer2019.pdf}
}

@article{Studer2019,
 abstract = {Automatic analysis of scanned historical documents  comprises a wide range of image analysis tasks, which are  often challenging for machine learning due to a lack of  humanannotated learning samples. With the advent of deep  neural networks, a promising way to cope with the lack of  training data is to pre-train models on images from a  different domain and then fine-tune them on historical  documents. In the current research, a typical example of  such cross-domain transfer learning is the use of neural  networks that have been pre-trained on the ImageNet  database for object recognition. It remains a mostly open  question whether or not this pre-training helps to analyse  historical documents, which have fundamentally different  image properties when compared with ImageNet. In this  paper, we present a comprehensive empirical survey on the  effect of ImageNet pretraining for diverse historical  document analysis tasks, including character recognition,  style classification, manuscript dating, semantic  segmentation, and content-based retrieval. While we obtain  mixed results for semantic segmentation at pixel-level, we  observe a clear trend across different network  architectures that ImageNet pre-training has a positive  effect on classification as well as content-based  retrieval.},
 address = {Sydney, New South Wales, Australia. 2019-09},
 author = {Studer, Linda and Alberti, Michele and Pondenkandath,  Vinaychandran and Goktepe, Pinar and Kolonko, Thomas and  Fischer, Andreas and Liwicki, Marcus and Ingold, Rolf},
 journal = {Proceedings of ICDAR 2019 : 15th International Conference  on Document Analysis and Recognition, 20-25 September 2019,  Sydney, New South Wales, Australia},
 number = {CONFERENCE},
 pages = {6 p.},
 publisher = {20-25 september 2019},
 recid = {4557},
 title = {A comprehensive study of ImageNet pre-training for  historical document image analysis},
 url = {/research/papers/Studer2019.pdf}
}

@article{Studer2019,
 address = {Luzern, Switzerland. 2019-11},
 author = {Studer, Linda and Toneyan, Shushan and Zlobec, Inti and  Lugli, Alessandro and Fischer, Andreas and Dawson, Heather},
 doi = {https://doi.org/10.1007/s00292-019-00679-6},
 journal = {Proceedings of the  4th Joint Annual Meeting of the Swiss  and Austrian Societies of Pathology, 7-9 November 2019,  Luzern, Switzerland ; Der Pathologe},
 note = {Publihsed in Der Pathologe, no. 6(2019), article no. P21,  pp. 688-689},
 number = {CONFERENCE},
 pages = {3 p.},
 publisher = {7-9 November 2019},
 recid = {4636},
 title = {Intestinal gland classification from colorectal cancer  tissue images using graph-based methods},
 url = {/research/papers/Studer2019.pdf}
}

@article{Studer2020,
 abstract = {Tumour budding in colorectal cancer, defined as single  tumour cells or small clusters containing four or fewer  tumour cells, is a robust and independent biomarker of  aggressive tumour biology. On the basis of published data  in the literature, the evidence is certainly in favour of  reporting tumour budding in routine practice. One important  aspect of implementing tumour budding has been to establish  a standardised and evidence-based scoring method, as was  recommended by the International Tumour Budding Consensus  Conference (ITBCC) in 2016. Further developments have aimed  at establishing methods for automated tumour budding  assessment. A digital approach to scoring tumour buds has  great potential to assist in performing an objective  budding count but, like the manual consensus method, must  be validated and standardised. The aim of the present  review is to present general considerations behind the  ITBCC scoring method, and a broad overview of the current  situation and challenges regarding automated tumour budding  detection methods.},
 address = {2020-10},
 author = {Studer, Linda and Blank, Annika and Bokhorst, John-Melle  and Nagtegaal, Iris D. and Zlobec, Inti and Lugli,  Alessandro and Fischer, Andreas and Dawson, Heather},
 doi = {https://doi.org/10.1111/his.14267},
 journal = {Histopathology},
 number = {ARTICLE},
 pages = {9 p.},
 recid = {10971},
 title = {Taking tumour budding to the next frontier : a post  International Tumour Budding Consensus Conference (ITBCC)  2016 review},
 url = {/research/papers/Studer2020.pdf}
}

@article{Studer2020,
 abstract = {With the rise of graph neural networks, sometimes also  referred to as geometric deep learning, a range of new  types of network layers have been introduced. Since this is  a very recent development, the design of new architectures  relies a lot on intuition and trial-and-error. In this  paper, we evaluate the effect of adding graph pooling  layers to a network, which down-sample graphs, and evaluate  the performance on three different datasets. We find that  especially for smaller graphs, adding pooling layers should  be done with caution, as they can have a negative effect on  the overall performance.},
 address = {Luzern, Switzerland. 2020-06},
 author = {Studer, Linda and Wallau, Jannis and Ingold, Rolf and  Fischer, Andreas},
 doi = {https://doi.org/10.1109/SDS49233.2020.00021},
 journal = {Proceedings of the 7th Swiss Conference on Data Science  (SDS), 26 June 2020, Luzern, Switzerland},
 number = {CONFERENCE},
 pages = {2 p.},
 publisher = {26 June 2020},
 recid = {10974},
 title = {Effects of graph pooling layers on classification with  graph neural networks},
 url = {/research/papers/Studer2020.pdf}
}

@article{Studer2021,
 abstract = {We propose to classify intestinal glands as normal or  dysplastic using cell-graphs and graph-based deep learning  methods. Dysplastic intestinal glands can lead to  colorectal cancer, which is one of the three most common  cancer types in the world. In order to assess the cancer  stage and thus the treatment of a patient, pathologists  analyse tissue samples of affected patients. Among other  factors, they look at the changes in morphology of  different tissues, such as the intestinal glands.  Cell-graphs have a high representational power and can  describe topological and geometrical properties of  intestinal glands. However, classical graph-based methods  have a high computational complexity and there is only a  limited range of machine learning methods available. In  this paper, we propose Graph Neural Networks (GNNs) as an  efficient learning-based approach to classify cell-graphs.  We investigate different variants of so-called Message  Passing Neural Networks and compare them with a classical  graph-based approach based on approximated Graph Edit  Distance and k-nearest neighbours classifier. A promising  classification accuracy of 94.8% is achieved by the  proposed method on the pT1 Gland Graph dataset, which is an  increase of 11.5% over the baseline result.},
 address = {Milan, Italy. 2021-01},
 author = {Studer, Linda and Wallau, Janis and Dawson, Heather and  Zlobec, Inti and Fischer, Andreas},
 doi = {https://doi.org/10.1109/ICPR48806.2021.9412535},
 journal = {Proceedings of the 25th International Conference on  Pattern Recognition (ICPR), 10-15 January 2021, Milan,  Italy},
 number = {CONFERENCE},
 pages = {8 p.},
 publisher = {10-15 January 2021},
 recid = {10970},
 title = {Classification of intestinal gland cell-graphs using graph  neural networks},
 url = {/research/papers/Studer2021.pdf}
}

@article{Studer2022,
 address = {Berlin, Germany. 2022-06},
 author = {Studer, Linda and Bokhorst, John-Melle and Ciompi,  Francesco and Fischer, Andreas and Dawson, Heather},
 journal = {Proceedings of the ECDP 2022 18th European Congress on  Digital Pathology, 15-18 June 2022, Berlin, Germany},
 number = {CONFERENCE},
 pages = {1 p.},
 publisher = {15-18 June 2022},
 recid = {11020},
 title = {Building-T-cell score is a potential predictor for more  aggressive treatment in pT1 colorectal cancers},
 url = {/research/papers/Studer2022.pdf}
}

@article{Studer2023,
 abstract = {Colon resection is often the treatment of choice for  colorectal cancer (CRC) patients. However, especially for  minimally invasive cancer, such as pT1, simply removing the  polyps may be enough to stop cancer progression. Different  histopathological risk factors such as tumor grade and  invasion depth currently found the basis for the need for  colon resection in pT1 CRC patients. Here, we investigate  two additional risk factors, tumor budding and lymphocyte  infiltration at the invasive front, which are known to be  clinically relevant. We capture the spatial layout of tumor  buds and T-cells and use graph-based deep learning to  investigate them as potential risk predictors. Our pT1  Hotspot Tumor Budding T-cell Graph (pT1-HBTG) dataset  consists of 626 tumor budding hotspots from 575 patients.  We propose and compare three different graph structures, as  well as combinations of the node labels. The  best-performing Graph Neural Network architecture is able  to increase specificity by 20% compared to the currently  recommended risk stratification based on histopathological  risk factors, without losing any sensitivity. We believe  that using a graph-based analysis can help to assist  pathologists in making risk assessments for pT1 CRC  patients, and thus decrease the number of patients  undergoing potentially unnecessary surgery. Both the code  and dataset are made publicly available.},
 address = {2023-07},
 author = {Studer, Linda and Bokhorst, John-Melle and Nagtegaal, Iris  and Zlobec, Inti and Dawson, Heather and Fischer, Andreas},
 journal = {Proceedings of Medical Imaging with Deep Learning (MIDL),  10-12 July 2023, Nashville, USA},
 number = {CONFERENCE},
 pages = {25 p.},
 recid = {13141},
 title = {Tumor budding t-cell graphs : assessing the need for  resection in pT1 colorectal cancer patients},
 url = {/research/papers/Studer2023.pdf}
}

@article{Vötglin2023,
 abstract = {Deep learning methods have shown strong performance in  solving tasks for historical document image analysis.  However, despite current libraries and frameworks,  programming an experiment or a set of experiments and  executing them can be time-consuming. This is why we  propose an open-source deep learning framework, DIVA-DAF,  which is based on PyTorch Lightning and specifically  designed for historical document analysis. Pre-implemented  tasks such as segmentation and classification can be easily  used or customized. It is also easy to create one’s own  tasks with the benefit of powerful modules for loading  data, even large data sets, and different forms of ground  truth. The applications conducted have demonstrated time  savings for the programming of a document analysis task, as  well as for different scenarios such as pre-training or  changing the architecture. Thanks to its data module, the  framework also allows to reduce the time of model training  significantly.},
 address = {2023-08},
 author = {Vötglin, Lars and Scius-Bertrand, Anna and Maergner, Paul  and Fischer, Andreas and Ingold, Rolf},
 doi = {https://doi.org/10.1145/3604951.3605511},
 journal = {Proceedings of the 7th International Workshop on  Historical Document Imaging and Processing (HIP'23), 25-26  August 2023, San José, CA, USA},
 note = {SCIUS-BERTRAND, Anna est chercheuse à la HES-SO, HEIA-FR,  depuis 2019. FISCHER, Andreas est chercheur à la HES-SO,  HEIA-FR, depuis 2015.},
 number = {CONFERENCE},
 pages = {6 p.},
 recid = {13143},
 title = {DIVA-DAF : a deep learning framework for historical  document image analysis},
 url = {/research/papers/Vötglin2023.pdf}
}

@article{Wei2015,
 abstract = {Automatic layout analysis of historical documents has to  cope with a large number of different scripts, writing  supports, and digitalization qualities. Under these  conditions, the design of robust features for machine  learning is a highly challenging task. We use convolutional  autoencoders to learn features from the images. In order to  increase the classification accuracy and to reduce the  feature dimension, in this paper we propose a novel feature  selection method. The method cascades adapted versions of  two conventional methods. Compared to three conventional  methods and our previous work, the proposed method achieves  a higher classification accuracy in most cases, while  maintaining low feature dimension. In addition, we find  that a significant number of autoencoder features are  redundant or irrelevant for the classification, and we give  our explanations. To the best of our knowledge, this paper  is one of the first investigations in the field of image  processing on the detection of redundancy and irrelevance  of autoencoder features using feature selection.},
 address = {Nancy, France. 2015-08},
 author = {Wei, Hao and Seuret, Mathias and Chen, Kai and Fischer,  Andreas and Liwicki, Marcus and Ingold, Rolf},
 doi = {https://doi.org/10.1145/2809544.2809548},
 journal = {Proceedings of HIP '15: Proceedings of the 3rd  International Workshop on Historical Document Imaging and  Processing, 22 August 2015, Nancy, France},
 number = {CONFERENCE},
 pages = {8 p.},
 publisher = {22 August 2015},
 recid = {10897},
 title = {Selecting Autoencoder Features for Layout Analysis of  Historical Documents},
 url = {/research/papers/Wei2015.pdf}
}

@article{Wicht2016,
 abstract = {Although Graphics Processing Units (GPUs) seem to  currently be the best platform to train machine learning  models, most research laboratories are still only equipped  with standard CPU systems. In this paper, we investigate  multiple techniques to speedup the training of Restricted  Boltzmann Machine (RBM) models and Convolutional RBM (CRBM)  models on CPU with the Contrastive Divergence (CD)  algorithm. Experimentally, we show that the proposed  techniques can reduce the training time by up to 30 times  for RBM and up to 12 times for CRBM, on a data set of  handwritten digits.},
 address = {Ulm, Germany. 2016-09},
 author = {Wicht, Baptiste and Fischer, Andreas and Hennebert, Jean},
 doi = {https://doi.org/10.1007/978-3-319-46182-3_14},
 journal = {Proceedings of the 7th IAPR TC3 Workshop, Artificial  Neural Networks in Pattern Recognition (ANNPR) 2016, 28-30  September 2016, Ulm Germany},
 number = {CONFERENCE},
 pages = {pp. 163-174},
 publisher = {28-30 September 2016},
 recid = {11054},
 title = {On CPU performance optimization of restricted Boltzmann  machine and convolutional RBM},
 url = {/research/papers/Wicht2016.pdf}
}

@article{Wicht2016,
 abstract = {To spot keywords on handwritten documents, we present a  hybrid keyword spotting system, based on features extracted  with Convolutional Deep Belief Networks and using Dynamic  Time Warping for word scoring. Features are learned from  word images, in an unsupervised manner, using a sliding  window to extract horizontal patches. For two single writer  historical data sets, it is shown that the proposed learned  feature extractor outperforms two standard sets of  features.},
 address = {Barcelona, Spain. 2016-09},
 author = {Wicht, Pascal and Fischer, Andreas and Hennebert, Jean},
 doi = {https://doi.org/10.1007/978-3-319-44781-0_14},
 journal = {Proceedings of the 25th International Conference on  Artificial Neural Networks and Machine Learning (ICANN),  6-9 September 2016, Barcelona, Spain},
 number = {CONFERENCE},
 pages = {pp. 113-120},
 publisher = {6-9 September 2016},
 recid = {11055},
 title = {Keyword spotting with convolutional deep belief networks  and dynamic time warping},
 url = {/research/papers/Wicht2016.pdf}
}

@article{Wicht2016,
 abstract = {Deep learning had a significant impact on diverse pattern  recognition tasks in the recent past. In this paper, we  investigate its potential for keyword spotting in  handwritten documents by designing a novel feature  extraction system based on Convolutional Deep Belief  Networks. Sliding window features are learned from word  images in an unsupervised manner. The proposed features are  evaluated both for template-based word spotting with  Dynamic Time Warping and for learning-based word spotting  with Hidden Markov Models. In an experimental evaluation on  three benchmark data sets with historical and modern  handwriting, it is shown that the proposed learned features  outperform three standard sets of handcrafted features.},
 address = {Cancun, Mexico. 2016-12},
 author = {Wicht, Baptiste and Fischer, Andreas and Hennebert, Jean},
 doi = {https://doi.org/10.1109/ICPR.2016.7900165},
 journal = {Proceedings of the 2016 23rd International Conference on  Pattern Recognition (ICPR), 4-8 December 2016, Cancun,  Mexico},
 number = {CONFERENCE},
 pages = {pp. 3434-3439},
 publisher = {4-8 December 2016},
 recid = {11056},
 title = {Deep learning features for handwritten keyword spotting},
 url = {/research/papers/Wicht2016.pdf}
}

@article{Wicht2018,
 abstract = {Expression Templates is a technique allowing to write  linear algebra code in C++ the same way it would be written  on paper. It is also used extensively as a performance  optimization technique, especially as the Smart Expression  Templates form which allows for even higher performance. It  has proved to be very efficient for computation on a  Central Processing Unit (CPU). However, due to its design,  it is not easily implemented on a Graphics Processing Unit  (GPU). In this paper, we devise a set of techniques to  allow the seamless evaluation of Smart Expression Templates  on the GPU. The execution is transparent for the user of  the library which still uses the matrices and vector as if  it was on the CPU and profits from the performance and  higher multi-processing capabilities of the GPU. We also  show that the GPU version is significantly faster than the  CPU version, without any change to the code of the user.},
 address = {Orléans, France. 2018-07},
 author = {Wicht, Baptiste and Fischer, Andreas and Hennebert, Jean},
 doi = {https://doi.org/10.1109/HPCS.2018.00045},
 journal = {Proceedings of the 2018 International Conference on High  Performance Computing &amp; Simulation (HPCS 2018), The 16th  Annual Meeting, 16-20 July 2018, Orléans, France},
 number = {CONFERENCE},
 pages = {8 p.},
 publisher = {16-20 July 2018},
 recid = {3229},
 title = {Seamless GPU evaluation of smart expression templates},
 url = {/research/papers/Wicht2018.pdf}
}

@article{Wicht2018,
 abstract = {Deep Learning Library (DLL) is a library for machine  learning with deep neural networks that focuses on speed.  It supports feedforward neural networks such as  fully-connected Artificial Neural Networks (ANNs) and  Convolutional Neural Networks (CNNs). Our main motivation  for this work was to propose and evaluate novel software  engineering strategies with potential to accelerate runtime  for training and inference. Such strategies are mostly  independent of the underlying deep learning algorithms. On  three different datasets and for four different neural  network models, we compared DLL to five popular deep  learning libraries. Experimentally, it is shown that the  proposed library is systematically and significantly faster  on CPU and GPU. In terms of classification performance,  similar accuracies as the other libraries are reported.},
 address = {Cham. 2018-08},
 author = {Wicht, Baptiste and Fischer, Andreas and Hennebert, Jean},
 doi = {https://doi.org/10.1007/978-3-319-99978-4_4},
 journal = {Lecture Notes in Computer Science},
 number = {CHAPTER},
 pages = {12 p.},
 publisher = {Springer},
 recid = {3234},
 title = {DLL : a fast deep neural network library},
 url = {/research/papers/Wicht2018.pdf}
}

@article{Zayene2021,
 abstract = {After the success of the two first editions of the “Arabic  Text in Videos Competition—AcTiVComp”, we are proposing to  organize a new edition in conjunction with the 25th  International Conference on Pattern Recognition (ICPR’20).  The main objective is to contribute in the research field  of text detection and recognition in multimedia documents,  with a focus on Arabic text in video frames. The former  editions were held in the framework of ICPR’16 and ICDAR’17  conferences. The obtained results on the AcTiV dataset have  shown that there is still room for improvement in both text  detection and recognition tasks. Four groups with five  systems are participating to this edition of AcTiVComp  (three for the detection task and two for the recognition  task). All the submitted systems have followed a CRNN-based  architecture, which is now the de facto choice for text  detection and OCR problems. The achieved results are very  interesting, showing a significant improvement from the  state-of-the-art performances on this field of research.},
 address = {Virtual Event. 2021-01},
 author = {Zayene, Oussama and Ingold, Rolf and Essoukri BenAmara,  Najoua and Hennebert, Jean},
 doi = {https://doi.org/10.1007/978-3-030-68793-9_26},
 journal = {Proceedings of International Conference on Pattern  Recognition, ICPR 2021: Pattern Recognition, CPR  International Workshops and Challenges, 10-15 January 2021,  Virtual Event},
 number = {CONFERENCE},
 pages = {pp. 343-356},
 publisher = {10-15 January 2021},
 recid = {7720},
 title = {ICPR2020 competition on text detection and recognition in  arabic news video frames},
 url = {/research/papers/Zayene2021.pdf}
}
